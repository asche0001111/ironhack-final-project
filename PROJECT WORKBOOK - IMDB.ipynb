{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1aea905-3170-410c-ac52-1098790c05d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73528f5-2eb0-4412-acda-75fc866854e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"imdb-movies-dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5d98504-7812-44a7-8641-b10137d9d17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Poster</th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Certificate</th>\n",
       "      <th>Duration (min)</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Metascore</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Votes</th>\n",
       "      <th>Description</th>\n",
       "      <th>Review Count</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Review</th>\n",
       "      <th>preprocessed_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BYWRkZj...</td>\n",
       "      <td>The Idea of You</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>R</td>\n",
       "      <td>115.0</td>\n",
       "      <td>[Comedy, Drama, Romance]</td>\n",
       "      <td>6.4</td>\n",
       "      <td>67.0</td>\n",
       "      <td>Michael Showalter</td>\n",
       "      <td>Anne Hathaway, Nicholas Galitzine, Ella Rubin,...</td>\n",
       "      <td>28,744</td>\n",
       "      <td>Solène, a 40-year-old single mom, begins an un...</td>\n",
       "      <td>166</td>\n",
       "      <td>Hypocrisy as an idea</td>\n",
       "      <td>This film, as well as the reaction to it, is a...</td>\n",
       "      <td>solène single mom begins unexpected romance ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BZGI4NT...</td>\n",
       "      <td>Kingdom of the Planet of the Apes</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>145.0</td>\n",
       "      <td>[Action, Adventure, Sci-Fi]</td>\n",
       "      <td>7.3</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Wes Ball</td>\n",
       "      <td>Owen Teague, Freya Allan, Kevin Durand, Peter ...</td>\n",
       "      <td>22,248</td>\n",
       "      <td>Many years after the reign of Caesar, a young ...</td>\n",
       "      <td>183</td>\n",
       "      <td>A phenomenal start to another trilogy!</td>\n",
       "      <td>I'm a big fan of all the planet of the apes, a...</td>\n",
       "      <td>many years reign caesar young ape goes journey...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BZjIyOT...</td>\n",
       "      <td>Unfrosted</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>97.0</td>\n",
       "      <td>[Biography, Comedy, History]</td>\n",
       "      <td>5.5</td>\n",
       "      <td>42.0</td>\n",
       "      <td>Jerry Seinfeld</td>\n",
       "      <td>Isaac Bae, Jerry Seinfeld, Chris Rickett, Rach...</td>\n",
       "      <td>18,401</td>\n",
       "      <td>In 1963 Michigan, business rivals Kellogg's an...</td>\n",
       "      <td>333</td>\n",
       "      <td>not funny</td>\n",
       "      <td>Pretty much the worst criticism you can lay on...</td>\n",
       "      <td>michigan business rivals kellogg post compete ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BMjA5Zj...</td>\n",
       "      <td>The Fall Guy</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>126.0</td>\n",
       "      <td>[Action, Comedy, Drama]</td>\n",
       "      <td>7.3</td>\n",
       "      <td>73.0</td>\n",
       "      <td>David Leitch</td>\n",
       "      <td>Ryan Gosling, Emily Blunt, Aaron Taylor-Johnso...</td>\n",
       "      <td>38,953</td>\n",
       "      <td>A down-and-out stuntman must find the missing ...</td>\n",
       "      <td>384</td>\n",
       "      <td>Everything you needed and more!</td>\n",
       "      <td>Just got out of the Austin premier at SXSW and...</td>\n",
       "      <td>stuntman must find missing star blockbuster film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BNTk1MT...</td>\n",
       "      <td>Challengers</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>R</td>\n",
       "      <td>131.0</td>\n",
       "      <td>[Drama, Romance, Sport]</td>\n",
       "      <td>7.7</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Luca Guadagnino</td>\n",
       "      <td>Zendaya, Mike Faist, Josh O'Connor, Darnell Ap...</td>\n",
       "      <td>32,517</td>\n",
       "      <td>Tashi, a former tennis prodigy turned coach, t...</td>\n",
       "      <td>194</td>\n",
       "      <td>Watch \"Match Point\" instead</td>\n",
       "      <td>This is a tough one. I liked the concept and t...</td>\n",
       "      <td>tashi former tennis prodigy turned coach turne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BMzg5MW...</td>\n",
       "      <td>The Greatest Show on Earth</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>U</td>\n",
       "      <td>152.0</td>\n",
       "      <td>[Drama, Family, Romance]</td>\n",
       "      <td>6.5</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Cecil B. DeMille</td>\n",
       "      <td>James Stewart, Charlton Heston, Betty Hutton, ...</td>\n",
       "      <td>16,078</td>\n",
       "      <td>The dramatic lives of trapeze artists, a clown...</td>\n",
       "      <td>128</td>\n",
       "      <td>Hey, doesn't anyone remember Last Emperor?</td>\n",
       "      <td>It constantly amazes me that people carp that ...</td>\n",
       "      <td>dramatic lives trapeze artists clown elephant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BYzA0ZG...</td>\n",
       "      <td>Berserk: Ougon Jidai-hen I - Haou no Tamago</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.0</td>\n",
       "      <td>[Animation, Action, Adventure]</td>\n",
       "      <td>7.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toshiyuki Kubooka</td>\n",
       "      <td>Hiroaki Iwanaga, Carrie Keranen, Takahiro Saku...</td>\n",
       "      <td>14,300</td>\n",
       "      <td>A lone sellsword named Guts gets recruited int...</td>\n",
       "      <td>12</td>\n",
       "      <td>Masterfully directed climatic epic saga</td>\n",
       "      <td>Few stories can capture your mind and soul in ...</td>\n",
       "      <td>lone sellsword named guts gets recruited merce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BM2U1Mj...</td>\n",
       "      <td>Is-slottet</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>[Mystery, Drama]</td>\n",
       "      <td>6.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Per Blom</td>\n",
       "      <td>Line Storesund, Hilde Nyeggen Martinsen, Meret...</td>\n",
       "      <td>740</td>\n",
       "      <td>A couple of twelve-year-old Norwegian girls st...</td>\n",
       "      <td>4</td>\n",
       "      <td>Beautiful Film</td>\n",
       "      <td>This film might not be to everyone's taste, it...</td>\n",
       "      <td>couple norwegian girls struggle intense taboo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BMTAwOD...</td>\n",
       "      <td>Loving Pablo</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>A</td>\n",
       "      <td>123.0</td>\n",
       "      <td>[Biography, Crime, Drama]</td>\n",
       "      <td>6.4</td>\n",
       "      <td>42.0</td>\n",
       "      <td>Fernando León de Aranoa</td>\n",
       "      <td>Javier Bardem, Penélope Cruz, Peter Sarsgaard,...</td>\n",
       "      <td>22,447</td>\n",
       "      <td>A journalist strikes up a romantic relationshi...</td>\n",
       "      <td>84</td>\n",
       "      <td>That film should be in Spanish</td>\n",
       "      <td>Why anyone (the director?) made Spanish actors...</td>\n",
       "      <td>journalist strikes romantic relationship notor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BMmE4ZD...</td>\n",
       "      <td>Un homme et une femme</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.0</td>\n",
       "      <td>[Drama, Romance]</td>\n",
       "      <td>7.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Claude Lelouch</td>\n",
       "      <td>Anouk Aimée, Jean-Louis Trintignant, Pierre Ba...</td>\n",
       "      <td>11,826</td>\n",
       "      <td>A widow and a widower find their relationship ...</td>\n",
       "      <td>61</td>\n",
       "      <td>Moved me tremendously.</td>\n",
       "      <td>This is a movie that resonated to my core.  I ...</td>\n",
       "      <td>widow widower find relationship developing lov...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Poster  \\\n",
       "0     https://m.media-amazon.com/images/M/MV5BYWRkZj...   \n",
       "1     https://m.media-amazon.com/images/M/MV5BZGI4NT...   \n",
       "2     https://m.media-amazon.com/images/M/MV5BZjIyOT...   \n",
       "3     https://m.media-amazon.com/images/M/MV5BMjA5Zj...   \n",
       "4     https://m.media-amazon.com/images/M/MV5BNTk1MT...   \n",
       "...                                                 ...   \n",
       "9995  https://m.media-amazon.com/images/M/MV5BMzg5MW...   \n",
       "9996  https://m.media-amazon.com/images/M/MV5BYzA0ZG...   \n",
       "9997  https://m.media-amazon.com/images/M/MV5BM2U1Mj...   \n",
       "9998  https://m.media-amazon.com/images/M/MV5BMTAwOD...   \n",
       "9999  https://m.media-amazon.com/images/M/MV5BMmE4ZD...   \n",
       "\n",
       "                                            Title    Year Certificate  \\\n",
       "0                                 The Idea of You  2023.0           R   \n",
       "1               Kingdom of the Planet of the Apes  2023.0       PG-13   \n",
       "2                                       Unfrosted  2023.0       PG-13   \n",
       "3                                    The Fall Guy  2023.0       PG-13   \n",
       "4                                     Challengers  2023.0           R   \n",
       "...                                           ...     ...         ...   \n",
       "9995                   The Greatest Show on Earth  2020.0           U   \n",
       "9996  Berserk: Ougon Jidai-hen I - Haou no Tamago  2020.0         NaN   \n",
       "9997                                   Is-slottet  2020.0         NaN   \n",
       "9998                                 Loving Pablo  2020.0           A   \n",
       "9999                        Un homme et une femme  2020.0         NaN   \n",
       "\n",
       "      Duration (min)                           Genre  Rating  Metascore  \\\n",
       "0              115.0        [Comedy, Drama, Romance]     6.4       67.0   \n",
       "1              145.0     [Action, Adventure, Sci-Fi]     7.3       66.0   \n",
       "2               97.0    [Biography, Comedy, History]     5.5       42.0   \n",
       "3              126.0         [Action, Comedy, Drama]     7.3       73.0   \n",
       "4              131.0         [Drama, Romance, Sport]     7.7       82.0   \n",
       "...              ...                             ...     ...        ...   \n",
       "9995           152.0        [Drama, Family, Romance]     6.5       76.0   \n",
       "9996            76.0  [Animation, Action, Adventure]     7.5        NaN   \n",
       "9997            78.0                [Mystery, Drama]     6.5        NaN   \n",
       "9998           123.0       [Biography, Crime, Drama]     6.4       42.0   \n",
       "9999           102.0                [Drama, Romance]     7.5        NaN   \n",
       "\n",
       "                     Director  \\\n",
       "0           Michael Showalter   \n",
       "1                    Wes Ball   \n",
       "2              Jerry Seinfeld   \n",
       "3                David Leitch   \n",
       "4             Luca Guadagnino   \n",
       "...                       ...   \n",
       "9995         Cecil B. DeMille   \n",
       "9996        Toshiyuki Kubooka   \n",
       "9997                 Per Blom   \n",
       "9998  Fernando León de Aranoa   \n",
       "9999           Claude Lelouch   \n",
       "\n",
       "                                                   Cast   Votes  \\\n",
       "0     Anne Hathaway, Nicholas Galitzine, Ella Rubin,...  28,744   \n",
       "1     Owen Teague, Freya Allan, Kevin Durand, Peter ...  22,248   \n",
       "2     Isaac Bae, Jerry Seinfeld, Chris Rickett, Rach...  18,401   \n",
       "3     Ryan Gosling, Emily Blunt, Aaron Taylor-Johnso...  38,953   \n",
       "4     Zendaya, Mike Faist, Josh O'Connor, Darnell Ap...  32,517   \n",
       "...                                                 ...     ...   \n",
       "9995  James Stewart, Charlton Heston, Betty Hutton, ...  16,078   \n",
       "9996  Hiroaki Iwanaga, Carrie Keranen, Takahiro Saku...  14,300   \n",
       "9997  Line Storesund, Hilde Nyeggen Martinsen, Meret...     740   \n",
       "9998  Javier Bardem, Penélope Cruz, Peter Sarsgaard,...  22,447   \n",
       "9999  Anouk Aimée, Jean-Louis Trintignant, Pierre Ba...  11,826   \n",
       "\n",
       "                                            Description Review Count  \\\n",
       "0     Solène, a 40-year-old single mom, begins an un...          166   \n",
       "1     Many years after the reign of Caesar, a young ...          183   \n",
       "2     In 1963 Michigan, business rivals Kellogg's an...          333   \n",
       "3     A down-and-out stuntman must find the missing ...          384   \n",
       "4     Tashi, a former tennis prodigy turned coach, t...          194   \n",
       "...                                                 ...          ...   \n",
       "9995  The dramatic lives of trapeze artists, a clown...          128   \n",
       "9996  A lone sellsword named Guts gets recruited int...           12   \n",
       "9997  A couple of twelve-year-old Norwegian girls st...            4   \n",
       "9998  A journalist strikes up a romantic relationshi...           84   \n",
       "9999  A widow and a widower find their relationship ...           61   \n",
       "\n",
       "                                    Review Title  \\\n",
       "0                           Hypocrisy as an idea   \n",
       "1         A phenomenal start to another trilogy!   \n",
       "2                                      not funny   \n",
       "3                Everything you needed and more!   \n",
       "4                    Watch \"Match Point\" instead   \n",
       "...                                          ...   \n",
       "9995  Hey, doesn't anyone remember Last Emperor?   \n",
       "9996     Masterfully directed climatic epic saga   \n",
       "9997                              Beautiful Film   \n",
       "9998              That film should be in Spanish   \n",
       "9999                      Moved me tremendously.   \n",
       "\n",
       "                                                 Review  \\\n",
       "0     This film, as well as the reaction to it, is a...   \n",
       "1     I'm a big fan of all the planet of the apes, a...   \n",
       "2     Pretty much the worst criticism you can lay on...   \n",
       "3     Just got out of the Austin premier at SXSW and...   \n",
       "4     This is a tough one. I liked the concept and t...   \n",
       "...                                                 ...   \n",
       "9995  It constantly amazes me that people carp that ...   \n",
       "9996  Few stories can capture your mind and soul in ...   \n",
       "9997  This film might not be to everyone's taste, it...   \n",
       "9998  Why anyone (the director?) made Spanish actors...   \n",
       "9999  This is a movie that resonated to my core.  I ...   \n",
       "\n",
       "                               preprocessed_description  \n",
       "0     solène single mom begins unexpected romance ha...  \n",
       "1     many years reign caesar young ape goes journey...  \n",
       "2     michigan business rivals kellogg post compete ...  \n",
       "3      stuntman must find missing star blockbuster film  \n",
       "4     tashi former tennis prodigy turned coach turne...  \n",
       "...                                                 ...  \n",
       "9995  dramatic lives trapeze artists clown elephant ...  \n",
       "9996  lone sellsword named guts gets recruited merce...  \n",
       "9997  couple norwegian girls struggle intense taboo ...  \n",
       "9998  journalist strikes romantic relationship notor...  \n",
       "9999  widow widower find relationship developing lov...  \n",
       "\n",
       "[10000 rows x 16 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968a1302-ac2e-4625-85ac-718b81a5eb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Genre'] = df['Genre'].fillna('')\n",
    "df['Genre'] = df['Genre'].astype(str)\n",
    "df['Genre'] = df['Genre'].apply(lambda x: x.split(', '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f972a2d8-a35b-4e7a-9209-1673cd012d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    return preprocessed_text\n",
    "\n",
    "df['preprocessed_description'] = df['Description'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44e91e6-23bf-4647-8fe8-2ae86954885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['preprocessed_description'])\n",
    "mlb = MultiLabelBinarizer()\n",
    "genre_matrix = mlb.fit_transform(df['Genre'])\n",
    "combined_features = np.hstack((tfidf_matrix.toarray(), genre_matrix))\n",
    "cosine_sim = cosine_similarity(combined_features, combined_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5216230f-55f5-422f-bad3-512128190f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(title, cosine_sim=cosine_sim):\n",
    "    if title not in df['Title'].values:\n",
    "        return [\"Movie not found in the dataset.\"]\n",
    "    \n",
    "    idx = df[df['Title'] == title].index[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:4]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return df['Title'].iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d70e50-3df0-4cab-8c58-ab98e1ebd809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title_from_imdb_link(imdb_link):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "        'Accept-Language': 'en-US,en;q=0.5'\n",
    "    }\n",
    "    response = requests.get(imdb_link, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        title_tag = soup.find('h1')\n",
    "        if title_tag:\n",
    "            title = title_tag.text.strip()\n",
    "            return title\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780e3e74-628b-4311-a645-86aa86678dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_link = input('Please paste your IMDb link here: ')\n",
    "\n",
    "\n",
    "movie_title = get_title_from_imdb_link(imdb_link)\n",
    "print(f\"Extracted Title: {movie_title}\")\n",
    "\n",
    "\n",
    "if movie_title:\n",
    "    recommendations = get_recommendations(movie_title)\n",
    "    print(f\"Movies recommended for '{movie_title}':\")\n",
    "    for movie in recommendations:\n",
    "        print(movie)\n",
    "else:\n",
    "    print(\"Invalid IMDb link or movie not found in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c0a7e83-0c95-4c26-84e8-242847b01c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/akirichenko/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/akirichenko/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please paste your IMDb link here:  https://www.imdb.com/title/tt0144084/?ref_=nv_sr_srsg_0_tt_8_nm_0_q_american%2520ps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Title: American Psycho\n",
      "Movies recommended for 'American Psycho':\n",
      "Maniac\n",
      "<Response [200]>\n",
      "Title: Maniac\n",
      "Description: A psychopathic man goes on a killing and mutilation spree in New York City.\n",
      "IMDb Link: N/A\n",
      "\n",
      "Orphan: First Kill\n",
      "<Response [200]>\n",
      "Title: Orphan: First Kill\n",
      "Description: After orchestrating a brilliant escape from an Estonian psychiatric facility, Esther travels to America by impersonating the missing daughter of a wealthy family.\n",
      "IMDb Link: N/A\n",
      "\n",
      "La tua presenza nuda!\n",
      "<Response [200]>\n",
      "Title: La tua presenza nuda!\n",
      "Description: A wealthy author's second wife begins to suspect that her 12-year-old stepson may have murdered his mother, who mysteriously died in a bathtub accident.\n",
      "IMDb Link: N/A\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# NLTK setup\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load and preprocess dataset\n",
    "df = pd.read_csv(\"imdb-movies-dataset.csv\")\n",
    "df['Genre'] = df['Genre'].fillna('')\n",
    "df['Genre'] = df['Genre'].astype(str)\n",
    "df['Genre'] = df['Genre'].apply(lambda x: x.split(', '))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['preprocessed_description'] = df['Description'].apply(preprocess_text)\n",
    "\n",
    "# Feature extraction\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['preprocessed_description'])\n",
    "mlb = MultiLabelBinarizer()\n",
    "genre_matrix = mlb.fit_transform(df['Genre'])\n",
    "combined_features = np.hstack((tfidf_matrix.toarray(), genre_matrix))\n",
    "cosine_sim = cosine_similarity(combined_features, combined_features)\n",
    "\n",
    "def get_recommendations(title, cosine_sim=cosine_sim, df=df):\n",
    "    if title not in df['Title'].values:\n",
    "        return [\"Movie not found in the dataset.\"]\n",
    "    \n",
    "    idx = df[df['Title'] == title].index[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:4]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return df.iloc[movie_indices][['Title', 'Genre', 'Description']]\n",
    "\n",
    "def get_title_from_imdb_link(imdb_link):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "        'Accept-Language': 'en-US,en;q=0.5'\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(imdb_link, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        title_tag = soup.find('h1')\n",
    "        if title_tag:\n",
    "            return title_tag.text.strip()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching IMDb link: {e}\")\n",
    "    return None\n",
    "\n",
    "def search_imdb_for_movie(movie_title):\n",
    "    print(movie_title)\n",
    "    api_url = f\"http://www.omdbapi.com/?i={movie_title}&apikey=7d9eb382\"\n",
    "    response = requests.get(api_url)\n",
    "    print(response)\n",
    "    if response.status_code == 200:\n",
    "        movie_data = response.json()\n",
    "        if movie_data['Response'] == 'True':\n",
    "            return {\n",
    "                'Title': movie_data.get('Title', 'N/A'),\n",
    "                'Description': movie_data.get('Plot', 'N/A'),\n",
    "                'IMDb Link': f\"https://www.imdb.com/title/{movie_data.get('imdbID', '')}\"\n",
    "            }\n",
    "    return None\n",
    "\n",
    "def main():\n",
    "    imdb_link = input('Please paste your IMDb link here: ')\n",
    "    movie_title = get_title_from_imdb_link(imdb_link)\n",
    "    \n",
    "    if movie_title:\n",
    "        print(f\"Extracted Title: {movie_title}\")\n",
    "        recommendations = get_recommendations(movie_title)\n",
    "        print(f\"Movies recommended for '{movie_title}':\")\n",
    "        for idx, row in recommendations.iterrows():\n",
    "            movie_info = search_imdb_for_movie(row['Title'])\n",
    "            if movie_info:\n",
    "                print(f\"Title: {movie_info['Title']}\\n\"\n",
    "                      f\"Description: {movie_info['Description']}\\n\"\n",
    "                      f\"IMDb Link: {movie_info['IMDb Link']}\\n\")\n",
    "            else:\n",
    "                print(f\"Title: {row['Title']}\\nDescription: {row['Description']}\\nIMDb Link: N/A\\n\")\n",
    "    else:\n",
    "        print(\"Invalid IMDb link or movie not found in the dataset.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b99e00e-fb63-47ac-8b8b-8055b478b064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/akirichenko/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/akirichenko/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please paste your IMDb link here:  https://www.imdb.com/title/tt0144084/?ref_=nv_sr_srsg_0_tt_8_nm_0_q_american%2520ps\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_title_from_imdb_link' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 70\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid IMDb link or movie not found in the dataset.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 70\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[6], line 55\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m     54\u001b[0m     imdb_link \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease paste your IMDb link here: \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 55\u001b[0m     movie_title \u001b[38;5;241m=\u001b[39m get_title_from_imdb_link(imdb_link)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m movie_title:\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracted Title: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmovie_title\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_title_from_imdb_link' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# NLTK setup\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load and preprocess dataset\n",
    "df = pd.read_csv(\"imdb-movies-dataset.csv\")\n",
    "df['Genre'] = df['Genre'].fillna('')\n",
    "df['Genre'] = df['Genre'].astype(str)\n",
    "df['Genre'] = df['Genre'].apply(lambda x: x.split(', '))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['preprocessed_description'] = df['Description'].apply(preprocess_text)\n",
    "\n",
    "# Feature extraction\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['preprocessed_description'])\n",
    "mlb = MultiLabelBinarizer()\n",
    "genre_matrix = mlb.fit_transform(df['Genre'])\n",
    "combined_features = np.hstack((tfidf_matrix.toarray(), genre_matrix))\n",
    "cosine_sim = cosine_similarity(combined_features, combined_features)\n",
    "\n",
    "def get_recommendations(title, cosine_sim=cosine_sim, df=df):\n",
    "    if title not in df['Title'].values:\n",
    "        return [\"Movie not found in the dataset.\"]\n",
    "    \n",
    "    idx = df[df['Title'] == title].index[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:4]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return df.iloc[movie_indices]\n",
    "\n",
    "def main():\n",
    "    imdb_link = input('Please paste your IMDb link here: ')\n",
    "    movie_title = get_title_from_imdb_link(imdb_link)\n",
    "    \n",
    "    if movie_title:\n",
    "        print(f\"Extracted Title: {movie_title}\")\n",
    "        recommendations = get_recommendations(movie_title)\n",
    "        print(f\"Movies recommended for '{movie_title}':\")\n",
    "        for idx, row in recommendations.iterrows():\n",
    "            print(f\"Title: {row['Title']}\\n\"\n",
    "                  f\"Description: {row['Description']}\\n\"\n",
    "                  f\"Director: {row['Director']}\\n\"\n",
    "                  f\"Poster Link: {row['Poster']}\\n\")\n",
    "    else:\n",
    "        print(\"Invalid IMDb link or movie not found in the dataset.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82ba4de7-16bc-4e93-9fd3-d90b1075e889",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/akirichenko/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/akirichenko/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please paste your IMDb link here:  https://www.imdb.com/title/tt0073650/?ref_=nv_sr_srsg_0_tt_3_nm_5_q_salo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Title: Salò, or the 120 Days of Sodom\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 71\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid IMDb link or movie not found in the dataset.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 71\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[9], line 59\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m movie_title:\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracted Title: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmovie_title\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 59\u001b[0m     recommendations \u001b[38;5;241m=\u001b[39m get_recommendations(movie_title)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMovies recommended for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmovie_title\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m movie_title \u001b[38;5;129;01min\u001b[39;00m recommendations:\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# NLTK setup\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load and preprocess dataset\n",
    "df = pd.read_csv(\"imdb-movies-dataset.csv\")\n",
    "df['Genre'] = df['Genre'].fillna('')\n",
    "df['Genre'] = df['Genre'].astype(str)\n",
    "df['Genre'] = df['Genre'].apply(lambda x: x.split(', '))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['preprocessed_description'] = df['Description'].apply(preprocess_text)\n",
    "\n",
    "# Feature extraction\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['preprocessed_description'])\n",
    "mlb = MultiLabelBinarizer()\n",
    "genre_matrix = mlb.fit_transform(df['Genre'])\n",
    "combined_features = np.hstack((tfidf_matrix.toarray(), genre_matrix))\n",
    "cosine_sim = cosine_similarity(combined_features, combined_features)\n",
    "\n",
    "b\n",
    "\n",
    "def main():\n",
    "    imdb_link = input('Please paste your IMDb link here: ')\n",
    "    movie_title = get_title_from_imdb_link(imdb_link)\n",
    "    \n",
    "    if movie_title:\n",
    "        print(f\"Extracted Title: {movie_title}\")\n",
    "        recommendations = get_recommendations(movie_title)['Title']\n",
    "        print(f\"Movies recommended for '{movie_title}':\")\n",
    "        for movie_title in recommendations:\n",
    "            movie_info = df[df['Title'] == movie_title].iloc[0]\n",
    "            print(f\"Title: {movie_info['Title']}\\n\"\n",
    "                  f\"Description: {movie_info['Description']}\\n\"\n",
    "                  f\"Director: {movie_info['Director']}\\n\"\n",
    "                  f\"Poster Link: {movie_info['Poster']}\\n\")\n",
    "    else:\n",
    "        print(\"Invalid IMDb link or movie not found in the dataset.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8590265-6724-47f0-bd76-d7bc7aefc7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Movie not found in the dataset.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_recommendations(title, cosine_sim=cosine_sim, df=df):\n",
    "    if title not in df['Title'].values:\n",
    "        return [\"Movie not found in the dataset.\"]\n",
    "    \n",
    "    idx = df[df['Title'] == title].index[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:4]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return df.iloc[movie_indices]\n",
    "\n",
    "get_recommendations(\"Salò, or the 120 Days of Sodom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a2579c-0584-49f4-b607-06af238e3fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"Title\"] == \"Salò, or the 120 Days of Sodom\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7519934e-a651-46e6-bfc9-01a2a7ff4313",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/akirichenko/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/akirichenko/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please paste your IMDb link here:  https://www.imdb.com/title/tt0073650/?ref_=nv_sr_srsg_0_tt_3_nm_5_q_salo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie Title: Salò, or the 120 Days of Sodom\n",
      "DataFrame:                                            IMDb Link  \\\n",
      "0  https://www.imdb.com/title/tt0073650/?ref_=nv_...   \n",
      "\n",
      "                            Title  \\\n",
      "0  Salò, or the 120 Days of Sodom   \n",
      "\n",
      "                                         Description    Genre  \n",
      "0  In World War II Italy, four fascist libertines...  [Drama]  \n",
      "[6699, 4628, 7088]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "positional indexers are out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1676\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1675\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_take_with_is_copy(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1678\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:4088\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   4079\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4080\u001b[0m \u001b[38;5;124;03mInternal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[1;32m   4081\u001b[0m \u001b[38;5;124;03mattribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4086\u001b[0m \u001b[38;5;124;03mSee the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   4087\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 4088\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indices\u001b[38;5;241m=\u001b[39mindices, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   4089\u001b[0m \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:4068\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[0;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[1;32m   4064\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[1;32m   4065\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[1;32m   4066\u001b[0m     )\n\u001b[0;32m-> 4068\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mtake(\n\u001b[1;32m   4069\u001b[0m     indices,\n\u001b[1;32m   4070\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_block_manager_axis(axis),\n\u001b[1;32m   4071\u001b[0m     verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   4072\u001b[0m )\n\u001b[1;32m   4073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   4074\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4075\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:874\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[1;32m    873\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[axis]\n\u001b[0;32m--> 874\u001b[0m indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[1;32m    876\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexers/utils.py:282\u001b[0m, in \u001b[0;36mmaybe_convert_indices\u001b[0;34m(indices, n, verify)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m--> 282\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m indices\n",
      "\u001b[0;31mIndexError\u001b[0m: indices are out-of-bounds",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 100\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid IMDb link. Please provide a valid IMDb link.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 100\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[37], line 87\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame:\u001b[39m\u001b[38;5;124m\"\u001b[39m, df)\n\u001b[1;32m     86\u001b[0m movie_title \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mat[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 87\u001b[0m recommendations \u001b[38;5;241m=\u001b[39m get_recommendations(movie_title, df\u001b[38;5;241m=\u001b[39mdf)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(recommendations, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28mprint\u001b[39m(recommendations[\u001b[38;5;241m0\u001b[39m])\n",
      "Cell \u001b[0;32mIn[37], line 53\u001b[0m, in \u001b[0;36mget_recommendations\u001b[0;34m(title, cosine_sim, df)\u001b[0m\n\u001b[1;32m     51\u001b[0m movie_indices \u001b[38;5;241m=\u001b[39m [i[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m sim_scores]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(movie_indices)\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\u001b[38;5;241m.\u001b[39miloc[movie_indices][[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGenre\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDescription\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1153\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1150\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1152\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m-> 1153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_axis(maybe_callable, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1705\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# a list of integers\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[0;32m-> 1705\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_list_axis(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   1707\u001b[0m \u001b[38;5;66;03m# a single integer\u001b[39;00m\n\u001b[1;32m   1708\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1709\u001b[0m     key \u001b[38;5;241m=\u001b[39m item_from_zerodim(key)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1679\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_take_with_is_copy(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1678\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[39;00m\n\u001b[0;32m-> 1679\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositional indexers are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# NLTK setup\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load and preprocess dataset\n",
    "df = pd.read_csv(\"imdb-movies-dataset.csv\")\n",
    "df['Genre'] = df['Genre'].fillna('')\n",
    "df['Genre'] = df['Genre'].astype(str)\n",
    "df['Genre'] = df['Genre'].apply(lambda x: x.split(', '))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['preprocessed_description'] = df['Description'].apply(preprocess_text)\n",
    "\n",
    "# Feature extraction\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['preprocessed_description'])\n",
    "mlb = MultiLabelBinarizer()\n",
    "genre_matrix = mlb.fit_transform(df['Genre'])\n",
    "combined_features = np.hstack((tfidf_matrix.toarray(), genre_matrix))\n",
    "cosine_sim = cosine_similarity(combined_features, combined_features)\n",
    "\n",
    "def get_recommendations(title, cosine_sim=cosine_sim, df=df):\n",
    "    if title not in df['Title'].values:\n",
    "        fill_missing_info(df, get_imdb_id_from_link(title))\n",
    "        title = df.at[0, 'Title']\n",
    "    \n",
    "    idx = df[df['Title'] == title].index[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:4]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    print(movie_indices)\n",
    "    return df.iloc[movie_indices][['Title', 'Genre', 'Description']]\n",
    "\n",
    "def extract_imdb_id(imdb_link):\n",
    "    imdb_id = re.search(r'tt\\d+', imdb_link)\n",
    "    if imdb_id:\n",
    "        return imdb_id.group(0)\n",
    "    return None\n",
    "\n",
    "\n",
    "def fill_missing_info(df, imdb_id):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "        'Accept-Language': 'en-US,en;q=0.5'\n",
    "    }\n",
    "    api_url = f\"http://www.omdbapi.com/?i={imdb_id}&apikey=7d9eb382\"\n",
    "    response = requests.get(api_url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        movie_data = response.json()\n",
    "        if movie_data['Response'] == 'True':\n",
    "            df.at[0, 'Title'] = movie_data.get('Title', 'N/A')\n",
    "            df.at[0, 'Description'] = movie_data.get('Plot', 'N/A')\n",
    "            df.at[0, 'Genre'] = movie_data.get('Genre', 'N/A').split(', ')\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    imdb_link = input('Please paste your IMDb link here: ')\n",
    "    imdb_id = extract_imdb_id(imdb_link)\n",
    "    if imdb_id:\n",
    "        movie_info = {'IMDb Link': imdb_link, 'Title': '', 'Description': '', 'Genre': ''}\n",
    "        df = pd.DataFrame([movie_info])\n",
    "        fill_missing_info(df, imdb_id)\n",
    "        print(\"Movie Title:\", df.at[0, 'Title'])\n",
    "        print(\"DataFrame:\", df)\n",
    "        movie_title = df.at[0, 'Title']\n",
    "        recommendations = get_recommendations(movie_title, df=df)\n",
    "        if isinstance(recommendations, list):\n",
    "            print(recommendations[0])\n",
    "        else:\n",
    "            print(f\"Movies recommended for '{movie_title}':\")\n",
    "            for idx, row in recommendations.iterrows():\n",
    "                print(f\"Title: {row['Title']}\\n\"\n",
    "                      f\"Description: {row['Description']}\\n\"\n",
    "                      f\"Genre: {row['Genre']}\\n\")\n",
    "    else:\n",
    "        print(\"Invalid IMDb link. Please provide a valid IMDb link.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "adaad185-f4df-45ad-8a6a-8692b4ef0447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(title, cosine_sim=cosine_sim, df=df):\n",
    "    if title not in df['Title'].values:\n",
    "        fill_missing_info(df, get_imdb_id_from_link(title))\n",
    "        title = df.at[0, 'Title']\n",
    "    \n",
    "    idx = df[df['Title'] == title].index[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:4]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return movie_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a5df010-0214-4876-b644-2fc0d0ee7a43",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_imdb_id_from_link' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m get_recommendations(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSalò, or the 120 Days of Sodom\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[38], line 3\u001b[0m, in \u001b[0;36mget_recommendations\u001b[0;34m(title, cosine_sim, df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_recommendations\u001b[39m(title, cosine_sim\u001b[38;5;241m=\u001b[39mcosine_sim, df\u001b[38;5;241m=\u001b[39mdf):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m title \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues:\n\u001b[0;32m----> 3\u001b[0m         fill_missing_info(df, get_imdb_id_from_link(title))\n\u001b[1;32m      4\u001b[0m         title \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mat[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m     idx \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m title]\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_imdb_id_from_link' is not defined"
     ]
    }
   ],
   "source": [
    "get_recommendations(\"Salò, or the 120 Days of Sodom\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b05695a0-0c62-43cb-9a5f-1c0012b24f86",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m11000\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1153\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1150\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1152\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m-> 1153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_axis(maybe_callable, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1714\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1711\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index by location index with a non-integer key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1713\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[0;32m-> 1714\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_integer(key, axis)\n\u001b[1;32m   1716\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_ixs(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1647\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1645\u001b[0m len_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis))\n\u001b[1;32m   1646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis:\n\u001b[0;32m-> 1647\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle positional indexer is out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "df.iloc[11000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d12ea326-6162-492f-9083-f550d4536463",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "        'Accept-Language': 'en-US,en;q=0.5'\n",
    "    }\n",
    "api_url = f\"http://www.omdbapi.com/?i=tt0073650&apikey=7d9eb382\"\n",
    "response = requests.get(api_url, headers=headers)\n",
    "if response.status_code == 200:\n",
    "    movie_data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "96383696-f45f-406d-96b8-619bb56d9a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Title': 'Salò, or the 120 Days of Sodom',\n",
       " 'Year': '1975',\n",
       " 'Rated': 'TV-MA',\n",
       " 'Released': '10 Jan 1976',\n",
       " 'Runtime': '117 min',\n",
       " 'Genre': 'Drama',\n",
       " 'Director': 'Pier Paolo Pasolini',\n",
       " 'Writer': 'Pier Paolo Pasolini, Sergio Citti, Pupi Avati',\n",
       " 'Actors': 'Paolo Bonacelli, Giorgio Cataldi, Uberto Paolo Quintavalle',\n",
       " 'Plot': 'In World War II Italy, four fascist libertines round up nine adolescent boys and girls and subject them to 120 days of physical, mental, and sexual torture.',\n",
       " 'Language': 'Italian, French, German',\n",
       " 'Country': 'Italy, France',\n",
       " 'Awards': '1 win',\n",
       " 'Poster': 'https://m.media-amazon.com/images/M/MV5BMzljYjk2YzAtZmM1Mi00MzI2LTgyMGEtODEyNmY1OGQ2YjNmXkEyXkFqcGdeQXVyMzU4ODM5Nw@@._V1_SX300.jpg',\n",
       " 'Ratings': [{'Source': 'Internet Movie Database', 'Value': '5.8/10'},\n",
       "  {'Source': 'Rotten Tomatoes', 'Value': '71%'}],\n",
       " 'Metascore': 'N/A',\n",
       " 'imdbRating': '5.8',\n",
       " 'imdbVotes': '65,787',\n",
       " 'imdbID': 'tt0073650',\n",
       " 'Type': 'movie',\n",
       " 'DVD': 'N/A',\n",
       " 'BoxOffice': 'N/A',\n",
       " 'Production': 'N/A',\n",
       " 'Website': 'N/A',\n",
       " 'Response': 'True'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "86a0a978-13c0-4f95-92ba-5c63d1d42a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6699</th>\n",
       "      <td>Elizabethtown</td>\n",
       "      <td>[Comedy, Drama, Romance]</td>\n",
       "      <td>During a hometown memorial for his Kentucky-bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4628</th>\n",
       "      <td>Home Again</td>\n",
       "      <td>[Comedy, Drama, Romance]</td>\n",
       "      <td>Life for a single mom in Los Angeles takes an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7088</th>\n",
       "      <td>Ehrengard: The Art of Seduction</td>\n",
       "      <td>[Comedy, Drama, Romance]</td>\n",
       "      <td>When a self-appointed expert on love tries to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Title                     Genre  \\\n",
       "6699                    Elizabethtown  [Comedy, Drama, Romance]   \n",
       "4628                       Home Again  [Comedy, Drama, Romance]   \n",
       "7088  Ehrengard: The Art of Seduction  [Comedy, Drama, Romance]   \n",
       "\n",
       "                                            Description  \n",
       "6699  During a hometown memorial for his Kentucky-bo...  \n",
       "4628  Life for a single mom in Los Angeles takes an ...  \n",
       "7088  When a self-appointed expert on love tries to ...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[[6699, 4628, 7088]][[\"Title\",\"Genre\",\"Description\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9467dff9-a28b-4481-ae51-b57f2eea0404",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/akirichenko/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/akirichenko/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please paste your IMDb link here:  https://www.imdb.com/title/tt0073650/?ref_=nv_sr_srsg_0_tt_3_nm_5_q_salo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie Title: Salò, or the 120 Days of Sodom\n",
      "DataFrame:                                            IMDb Link  \\\n",
      "0  https://www.imdb.com/title/tt0073650/?ref_=nv_...   \n",
      "\n",
      "                            Title  \\\n",
      "0  Salò, or the 120 Days of Sodom   \n",
      "\n",
      "                                         Description    Genre  \n",
      "0  In World War II Italy, four fascist libertines...  [Drama]  \n",
      "6699\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# NLTK setup\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load and preprocess dataset\n",
    "df = pd.read_csv(\"imdb-movies-dataset.csv\")\n",
    "df['Genre'] = df['Genre'].fillna('')\n",
    "df['Genre'] = df['Genre'].astype(str)\n",
    "df['Genre'] = df['Genre'].apply(lambda x: x.split(', '))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['preprocessed_description'] = df['Description'].apply(preprocess_text)\n",
    "\n",
    "# Feature extraction\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['preprocessed_description'])\n",
    "mlb = MultiLabelBinarizer()\n",
    "genre_matrix = mlb.fit_transform(df['Genre'])\n",
    "combined_features = np.hstack((tfidf_matrix.toarray(), genre_matrix))\n",
    "cosine_sim = cosine_similarity(combined_features, combined_features)\n",
    "\n",
    "def get_recommendations(title, cosine_sim=cosine_sim, df=df):\n",
    "    if title not in df['Title'].values:\n",
    "        fill_missing_info(df, get_imdb_id_from_link(title))\n",
    "        title = df.at[0, 'Title']\n",
    "    \n",
    "    idx = df[df['Title'] == title].index[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:4]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return movie_indices\n",
    "\n",
    "def extract_imdb_id(imdb_link):\n",
    "    imdb_id = re.search(r'tt\\d+', imdb_link)\n",
    "    if imdb_id:\n",
    "        return imdb_id.group(0)\n",
    "    return None\n",
    "\n",
    "\n",
    "def fill_missing_info(df, imdb_id):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "        'Accept-Language': 'en-US,en;q=0.5'\n",
    "    }\n",
    "    api_url = f\"http://www.omdbapi.com/?i={imdb_id}&apikey=7d9eb382\"\n",
    "    response = requests.get(api_url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        movie_data = response.json()\n",
    "        if movie_data['Response'] == 'True':\n",
    "            df.at[0, 'Title'] = movie_data.get('Title', 'N/A')\n",
    "            df.at[0, 'Description'] = movie_data.get('Plot', 'N/A')\n",
    "            df.at[0, 'Genre'] = movie_data.get('Genre', 'N/A').split(', ')\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    imdb_link = input('Please paste your IMDb link here: ')\n",
    "    imdb_id = extract_imdb_id(imdb_link)\n",
    "    if imdb_id:\n",
    "        movie_info = {'IMDb Link': imdb_link, 'Title': '', 'Description': '', 'Genre': ''}\n",
    "        df = pd.DataFrame([movie_info])\n",
    "        fill_missing_info(df, imdb_id)\n",
    "        print(\"Movie Title:\", df.at[0, 'Title'])\n",
    "        print(\"DataFrame:\", df)\n",
    "        movie_title = df.at[0, 'Title']\n",
    "        recommendations = get_recommendations(movie_title, df=df)\n",
    "        if isinstance(recommendations, list):\n",
    "            print(recommendations[0])\n",
    "        else:\n",
    "            print(f\"Movies recommended for '{movie_title}':\")\n",
    "            for idx, row in recommendations.iterrows():\n",
    "                print(f\"Title: {row['Title']}\\n\"\n",
    "                      f\"Description: {row['Description']}\\n\"\n",
    "                      f\"Genre: {row['Genre']}\\n\")\n",
    "    else:\n",
    "        print(\"Invalid IMDb link. Please provide a valid IMDb link.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0bfd3b34-3d38-4f9f-b68c-cac0a88d603b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/akirichenko/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/akirichenko/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please paste your IMDb link here:  https://www.imdb.com/title/tt0073650/?ref_=nv_sr_srsg_0_tt_3_nm_5_q_salo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie Title: Salò, or the 120 Days of Sodom\n",
      "DataFrame: Poster                                                                    NaN\n",
      "Title                                          Salò, or the 120 Days of Sodom\n",
      "Year                                                                      NaN\n",
      "Certificate                                                               NaN\n",
      "Duration (min)                                                            NaN\n",
      "Genre                                                                 [Drama]\n",
      "Rating                                                                    NaN\n",
      "Metascore                                                                 NaN\n",
      "Director                                                                  NaN\n",
      "Cast                                                                      NaN\n",
      "Votes                                                                     NaN\n",
      "Description                 In World War II Italy, four fascist libertines...\n",
      "Review Count                                                              NaN\n",
      "Review Title                                                              NaN\n",
      "Review                                                                    NaN\n",
      "preprocessed_description    world war ii italy four fascist libertines rou...\n",
      "Name: 10000, dtype: object\n",
      "Movies recommended for 'Salò, or the 120 Days of Sodom':\n",
      "Title: Salò, or the 120 Days of Sodom\n",
      "Description: In World War II Italy, four fascist libertines round up nine adolescent boys and girls and subject them to 120 days of physical, mental, and sexual torture.\n",
      "Genre: ['Drama']\n",
      "\n",
      "Title: Melissa P.\n",
      "Description: An adolescent girl, living with her mother and her grandmother, will have her first sexual experiences in a heavy and excessive way.\n",
      "Genre: ['Drama']\n",
      "\n",
      "Title: The Subject Was Roses\n",
      "Description: A young man returning home from World War II finds himself caught up in his parents' turbulent relationship.\n",
      "Genre: ['Drama']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# NLTK setup\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load and preprocess dataset\n",
    "df = pd.read_csv(\"imdb-movies-dataset.csv\")\n",
    "df['Genre'] = df['Genre'].fillna('')\n",
    "df['Genre'] = df['Genre'].astype(str)\n",
    "df['Genre'] = df['Genre'].apply(lambda x: x.split(', '))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['preprocessed_description'] = df['Description'].apply(preprocess_text)\n",
    "\n",
    "# Feature extraction function\n",
    "def compute_features(df):\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(df['preprocessed_description'])\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    genre_matrix = mlb.fit_transform(df['Genre'])\n",
    "    combined_features = np.hstack((tfidf_matrix.toarray(), genre_matrix))\n",
    "    return combined_features\n",
    "\n",
    "combined_features = compute_features(df)\n",
    "cosine_sim = cosine_similarity(combined_features, combined_features)\n",
    "\n",
    "def get_recommendations(title, cosine_sim, df):\n",
    "    if title not in df['Title'].values:\n",
    "        return [\"Movie not found in the dataset.\"]\n",
    "    \n",
    "    idx = df[df['Title'] == title].index[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:4]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return df.iloc[movie_indices][['Title', 'Genre', 'Description']]\n",
    "\n",
    "def extract_imdb_id(imdb_link):\n",
    "    imdb_id = re.search(r'tt\\d+', imdb_link)\n",
    "    if imdb_id:\n",
    "        return imdb_id.group(0)\n",
    "    return None\n",
    "\n",
    "def fill_missing_info(df, imdb_id):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "        'Accept-Language': 'en-US,en;q=0.5'\n",
    "    }\n",
    "    api_url = f\"http://www.omdbapi.com/?i={imdb_id}&apikey=7d9eb382\"\n",
    "    response = requests.get(api_url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        movie_data = response.json()\n",
    "        if movie_data['Response'] == 'True':\n",
    "            new_movie = {\n",
    "                'Title': movie_data.get('Title', 'N/A'),\n",
    "                'Description': movie_data.get('Plot', 'N/A'),\n",
    "                'Genre': movie_data.get('Genre', 'N/A').split(', '),\n",
    "                'preprocessed_description': preprocess_text(movie_data.get('Plot', 'N/A'))\n",
    "            }\n",
    "            new_movie_df = pd.DataFrame([new_movie])\n",
    "            df = pd.concat([df, new_movie_df], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    imdb_link = input('Please paste your IMDb link here: ')\n",
    "    imdb_id = extract_imdb_id(imdb_link)\n",
    "    if imdb_id:\n",
    "        global df, combined_features, cosine_sim\n",
    "        df = fill_missing_info(df, imdb_id)\n",
    "        if not df.empty:\n",
    "            df['preprocessed_description'] = df['Description'].apply(preprocess_text)\n",
    "            combined_features = compute_features(df)\n",
    "            cosine_sim = cosine_similarity(combined_features, combined_features)\n",
    "            movie_title = df.iloc[-1]['Title']\n",
    "            print(\"Movie Title:\", movie_title)\n",
    "            print(\"DataFrame:\", df.iloc[-1])\n",
    "            recommendations = get_recommendations(movie_title, cosine_sim, df)\n",
    "            print(f\"Movies recommended for '{movie_title}':\")\n",
    "            for idx, row in recommendations.iterrows():\n",
    "                print(f\"Title: {row['Title']}\\n\"\n",
    "                      f\"Description: {row['Description']}\\n\"\n",
    "                      f\"Genre: {row['Genre']}\\n\")\n",
    "        else:\n",
    "            print(\"Failed to retrieve movie information from IMDb.\")\n",
    "    else:\n",
    "        print(\"Invalid IMDb link. Please provide a valid IMDb link.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "edcb7cc2-dfca-4d53-bcf0-ad6da7f053aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/akirichenko/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/akirichenko/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please paste your IMDb link here:  https://www.imdb.com/title/tt0144084/?ref_=nv_sr_srsg_0_tt_8_nm_0_q_american%2520ps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie Title: American Psycho\n",
      "DataFrame: Poster                                                                    NaN\n",
      "Title                                                         American Psycho\n",
      "Year                                                                      NaN\n",
      "Certificate                                                               NaN\n",
      "Duration (min)                                                            NaN\n",
      "Genre                                                  [Crime, Drama, Horror]\n",
      "Rating                                                                    NaN\n",
      "Metascore                                                                 NaN\n",
      "Director                                                                  NaN\n",
      "Cast                                                                      NaN\n",
      "Votes                                                                     NaN\n",
      "Description                 A wealthy New York City investment banking exe...\n",
      "Review Count                                                              NaN\n",
      "Review Title                                                              NaN\n",
      "Review                                                                    NaN\n",
      "preprocessed_description    wealthy new york city investment banking execu...\n",
      "Name: 10000, dtype: object\n",
      "Movies recommended for 'American Psycho':\n",
      "Title: American Psycho\n",
      "Description: A wealthy New York City investment banking executive, Patrick Bateman, hides his alternate psychopathic ego from his co-workers and friends as he delves deeper into his violent, hedonistic fantasies.\n",
      "Genre: ['Crime', 'Drama', 'Horror']\n",
      "\n",
      "Title: Maniac\n",
      "Description: A psychopathic man goes on a killing and mutilation spree in New York City.\n",
      "Genre: ['Crime', 'Drama', 'Horror']\n",
      "\n",
      "Title: Orphan: First Kill\n",
      "Description: After orchestrating a brilliant escape from an Estonian psychiatric facility, Esther travels to America by impersonating the missing daughter of a wealthy family.\n",
      "Genre: ['Crime', 'Drama', 'Horror']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# NLTK setup\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load and preprocess dataset\n",
    "df = pd.read_csv(\"imdb-movies-dataset.csv\")\n",
    "df['Genre'] = df['Genre'].fillna('')\n",
    "df['Genre'] = df['Genre'].astype(str)\n",
    "df['Genre'] = df['Genre'].apply(lambda x: x.split(', '))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['preprocessed_description'] = df['Description'].apply(preprocess_text)\n",
    "\n",
    "# Feature extraction function\n",
    "def compute_features(df):\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(df['preprocessed_description'])\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    genre_matrix = mlb.fit_transform(df['Genre'])\n",
    "    combined_features = np.hstack((tfidf_matrix.toarray(), genre_matrix))\n",
    "    return combined_features\n",
    "\n",
    "combined_features = compute_features(df)\n",
    "cosine_sim = cosine_similarity(combined_features, combined_features)\n",
    "\n",
    "def get_recommendations(title, cosine_sim, df):\n",
    "    if title not in df['Title'].values:\n",
    "        return [\"Movie not found in the dataset.\"]\n",
    "    \n",
    "    idx = df[df['Title'] == title].index[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = [score for score in sim_scores if score[0] != idx]  # Exclude the movie itself\n",
    "    sim_scores = sim_scores[:3]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return df.iloc[movie_indices][['Title', 'Genre', 'Description']]\n",
    "\n",
    "def extract_imdb_id(imdb_link):\n",
    "    imdb_id = re.search(r'tt\\d+', imdb_link)\n",
    "    if imdb_id:\n",
    "        return imdb_id.group(0)\n",
    "    return None\n",
    "\n",
    "def fill_missing_info(df, imdb_id):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "        'Accept-Language': 'en-US,en;q=0.5'\n",
    "    }\n",
    "    api_url = f\"http://www.omdbapi.com/?i={imdb_id}&apikey=7d9eb382\"\n",
    "    response = requests.get(api_url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        movie_data = response.json()\n",
    "        if movie_data['Response'] == 'True':\n",
    "            new_movie = {\n",
    "                'Title': movie_data.get('Title', 'N/A'),\n",
    "                'Description': movie_data.get('Plot', 'N/A'),\n",
    "                'Genre': movie_data.get('Genre', 'N/A').split(', '),\n",
    "                'preprocessed_description': preprocess_text(movie_data.get('Plot', 'N/A'))\n",
    "            }\n",
    "            new_movie_df = pd.DataFrame([new_movie])\n",
    "            df = pd.concat([df, new_movie_df], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    imdb_link = input('Please paste your IMDb link here: ')\n",
    "    imdb_id = extract_imdb_id(imdb_link)\n",
    "    if imdb_id:\n",
    "        global df, combined_features, cosine_sim\n",
    "        df = fill_missing_info(df, imdb_id)\n",
    "        if not df.empty:\n",
    "            df['preprocessed_description'] = df['Description'].apply(preprocess_text)\n",
    "            combined_features = compute_features(df)\n",
    "            cosine_sim = cosine_similarity(combined_features, combined_features)\n",
    "            movie_title = df.iloc[-1]['Title']\n",
    "            print(\"Movie Title:\", movie_title)\n",
    "            print(\"DataFrame:\", df.iloc[-1])\n",
    "            recommendations = get_recommendations(movie_title, cosine_sim, df)\n",
    "            print(f\"Movies recommended for '{movie_title}':\")\n",
    "            for idx, row in recommendations.iterrows():\n",
    "                print(f\"Title: {row['Title']}\\n\"\n",
    "                      f\"Description: {row['Description']}\\n\"\n",
    "                      f\"Genre: {row['Genre']}\\n\")\n",
    "        else:\n",
    "            print(\"Failed to retrieve movie information from IMDb.\")\n",
    "    else:\n",
    "        print(\"Invalid IMDb link. Please provide a valid IMDb link.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f7889de8-65db-4fbd-8a4b-5e39b2e7e4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/akirichenko/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/akirichenko/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please paste your IMDb link here:  https://www.imdb.com/title/tt0144084/?ref_=nv_sr_srsg_0_tt_8_nm_0_q_american%2520ps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie Title: American Psycho\n",
      "DataFrame: Poster                                                                    NaN\n",
      "Title                                                         American Psycho\n",
      "Year                                                                      NaN\n",
      "Certificate                                                               NaN\n",
      "Duration (min)                                                            NaN\n",
      "Genre                                                  [Crime, Drama, Horror]\n",
      "Rating                                                                    NaN\n",
      "Metascore                                                                 NaN\n",
      "Director                                                                  NaN\n",
      "Cast                                                                      NaN\n",
      "Votes                                                                     NaN\n",
      "Description                 A wealthy New York City investment banking exe...\n",
      "Review Count                                                              NaN\n",
      "Review Title                                                              NaN\n",
      "Review                                                                    NaN\n",
      "preprocessed_description    wealthy new york city investment banking execu...\n",
      "Name: 10000, dtype: object\n",
      "Movies recommended for 'American Psycho':\n",
      "Title: Maniac\n",
      "Description: A psychopathic man goes on a killing and mutilation spree in New York City.\n",
      "Genre: ['Crime', 'Drama', 'Horror']\n",
      "\n",
      "Title: Orphan: First Kill\n",
      "Description: After orchestrating a brilliant escape from an Estonian psychiatric facility, Esther travels to America by impersonating the missing daughter of a wealthy family.\n",
      "Genre: ['Crime', 'Drama', 'Horror']\n",
      "\n",
      "Title: La tua presenza nuda!\n",
      "Description: A wealthy author's second wife begins to suspect that her 12-year-old stepson may have murdered his mother, who mysteriously died in a bathtub accident.\n",
      "Genre: ['Crime', 'Drama', 'Horror']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# NLTK setup\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load and preprocess dataset\n",
    "df = pd.read_csv(\"imdb-movies-dataset.csv\")\n",
    "df['Genre'] = df['Genre'].fillna('')\n",
    "df['Genre'] = df['Genre'].astype(str)\n",
    "df['Genre'] = df['Genre'].apply(lambda x: x.split(', '))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['preprocessed_description'] = df['Description'].apply(preprocess_text)\n",
    "\n",
    "# Feature extraction function\n",
    "def compute_features(df):\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(df['preprocessed_description'])\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    genre_matrix = mlb.fit_transform(df['Genre'])\n",
    "    combined_features = np.hstack((tfidf_matrix.toarray(), genre_matrix))\n",
    "    return combined_features\n",
    "\n",
    "combined_features = compute_features(df)\n",
    "cosine_sim = cosine_similarity(combined_features, combined_features)\n",
    "\n",
    "def get_recommendations(title, cosine_sim, df):\n",
    "    if title not in df['Title'].values:\n",
    "        return [\"Movie not found in the dataset.\"]\n",
    "    \n",
    "    idx = df[df['Title'] == title].index[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:5]  # Get the second to fourth highest scores\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return df.iloc[movie_indices][['Title', 'Genre', 'Description']]\n",
    "\n",
    "def extract_imdb_id(imdb_link):\n",
    "    imdb_id = re.search(r'tt\\d+', imdb_link)\n",
    "    if imdb_id:\n",
    "        return imdb_id.group(0)\n",
    "    return None\n",
    "\n",
    "def fill_missing_info(df, imdb_id):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "        'Accept-Language': 'en-US,en;q=0.5'\n",
    "    }\n",
    "    api_url = f\"http://www.omdbapi.com/?i={imdb_id}&apikey=7d9eb382\"\n",
    "    response = requests.get(api_url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        movie_data = response.json()\n",
    "        if movie_data['Response'] == 'True':\n",
    "            new_movie = {\n",
    "                'Title': movie_data.get('Title', 'N/A'),\n",
    "                'Description': movie_data.get('Plot', 'N/A'),\n",
    "                'Genre': movie_data.get('Genre', 'N/A').split(', '),\n",
    "                'preprocessed_description': preprocess_text(movie_data.get('Plot', 'N/A'))\n",
    "            }\n",
    "            new_movie_df = pd.DataFrame([new_movie])\n",
    "            df = pd.concat([df, new_movie_df], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    imdb_link = input('Please paste your IMDb link here: ')\n",
    "    imdb_id = extract_imdb_id(imdb_link)\n",
    "    if imdb_id:\n",
    "        global df, combined_features, cosine_sim\n",
    "        df = fill_missing_info(df, imdb_id)\n",
    "        if not df.empty:\n",
    "            df['preprocessed_description'] = df['Description'].apply(preprocess_text)\n",
    "            combined_features = compute_features(df)\n",
    "            cosine_sim = cosine_similarity(combined_features, combined_features)\n",
    "            movie_title = df.iloc[-1]['Title']\n",
    "            print(\"Movie Title:\", movie_title)\n",
    "            print(\"DataFrame:\", df.iloc[-1])\n",
    "            recommendations = get_recommendations(movie_title, cosine_sim, df)\n",
    "            print(f\"Movies recommended for '{movie_title}':\")\n",
    "            recommended_titles = []\n",
    "            for idx, row in recommendations.iterrows():\n",
    "                if row['Title'] != movie_title and row['Title'] not in recommended_titles:\n",
    "                    recommended_titles.append(row['Title'])\n",
    "                    print(f\"Title: {row['Title']}\\n\"\n",
    "                          f\"Description: {row['Description']}\\n\"\n",
    "                          f\"Genre: {row['Genre']}\\n\")\n",
    "                    if len(recommended_titles) == 4:\n",
    "                        break\n",
    "        else:\n",
    "            print(\"Failed to retrieve movie information from IMDb.\")\n",
    "    else:\n",
    "        print(\"Invalid IMDb link. Please provide a valid IMDb link.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1c7689e7-7fba-4469-ba8e-77895fc4ee01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/akirichenko/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/akirichenko/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please paste your IMDb link here:  https://www.imdb.com/title/tt0144084/?ref_=nv_sr_srsg_0_tt_8_nm_0_q_american%2520ps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie Title: American Psycho\n",
      "DataFrame: Poster                                                                    NaN\n",
      "Title                                                         American Psycho\n",
      "Year                                                                      NaN\n",
      "Certificate                                                               NaN\n",
      "Duration (min)                                                            NaN\n",
      "Genre                                                  [Crime, Drama, Horror]\n",
      "Rating                                                                    NaN\n",
      "Metascore                                                                 NaN\n",
      "Director                                                                  NaN\n",
      "Cast                                                                      NaN\n",
      "Votes                                                                     NaN\n",
      "Description                 A wealthy New York City investment banking exe...\n",
      "Review Count                                                              NaN\n",
      "Review Title                                                              NaN\n",
      "Review                                                                    NaN\n",
      "preprocessed_description    wealthy new york city investment banking execu...\n",
      "Name: 10000, dtype: object\n",
      "Movies recommended for 'American Psycho':\n",
      "Title: Maniac\n",
      "Description: A psychopathic man goes on a killing and mutilation spree in New York City.\n",
      "Genre: ['Crime', 'Drama', 'Horror']\n",
      "Director: William Lustig\n",
      "Poster: https://m.media-amazon.com/images/M/MV5BNzliZTJmOWYtNWIyYi00ZTY4LThjNDMtZGQyMTNlZDRhMjFhXkEyXkFqcGdeQXVyMTUzMDUzNTI3._V1_UX140_CR0,0,140,209_AL_.jpg\n",
      "\n",
      "Title: Orphan: First Kill\n",
      "Description: After orchestrating a brilliant escape from an Estonian psychiatric facility, Esther travels to America by impersonating the missing daughter of a wealthy family.\n",
      "Genre: ['Crime', 'Drama', 'Horror']\n",
      "Director: William Brent Bell\n",
      "Poster: https://m.media-amazon.com/images/M/MV5BZjgwNDA3MmUtMTQ3Yy00ZDFmLTgwMTktNTBlMTQ3ZTI5MjYxXkEyXkFqcGdeQXVyMTM1MTE1NDMx._V1_UY209_CR0,0,140,209_AL_.jpg\n",
      "\n",
      "Title: La tua presenza nuda!\n",
      "Description: A wealthy author's second wife begins to suspect that her 12-year-old stepson may have murdered his mother, who mysteriously died in a bathtub accident.\n",
      "Genre: ['Crime', 'Drama', 'Horror']\n",
      "Director: James Kelley\n",
      "Poster: https://m.media-amazon.com/images/M/MV5BYzY1YzhiMWEtM2M0OS00MDAxLTg4ZGEtNzdlNTlmNTk3ZTBmXkEyXkFqcGdeQXVyOTI2MjI5MQ@@._V1_UY209_CR1,0,140,209_AL_.jpg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# NLTK setup\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load and preprocess dataset\n",
    "df = pd.read_csv(\"imdb-movies-dataset.csv\")\n",
    "df['Genre'] = df['Genre'].fillna('')\n",
    "df['Genre'] = df['Genre'].astype(str)\n",
    "df['Genre'] = df['Genre'].apply(lambda x: x.split(', '))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['preprocessed_description'] = df['Description'].apply(preprocess_text)\n",
    "\n",
    "# Feature extraction function\n",
    "def compute_features(df):\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(df['preprocessed_description'])\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    genre_matrix = mlb.fit_transform(df['Genre'])\n",
    "    combined_features = np.hstack((tfidf_matrix.toarray(), genre_matrix))\n",
    "    return combined_features\n",
    "\n",
    "combined_features = compute_features(df)\n",
    "cosine_sim = cosine_similarity(combined_features, combined_features)\n",
    "\n",
    "def get_recommendations(title, cosine_sim, df):\n",
    "    if title not in df['Title'].values:\n",
    "        return [\"Movie not found in the dataset.\"]\n",
    "    \n",
    "    idx = df[df['Title'] == title].index[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:5]  # Get the second to fourth highest scores\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return df.iloc[movie_indices][['Title', 'Genre', 'Description', 'Director', 'Poster']]\n",
    "\n",
    "def extract_imdb_id(imdb_link):\n",
    "    imdb_id = re.search(r'tt\\d+', imdb_link)\n",
    "    if imdb_id:\n",
    "        return imdb_id.group(0)\n",
    "    return None\n",
    "\n",
    "def fill_missing_info(df, imdb_id):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "        'Accept-Language': 'en-US,en;q=0.5'\n",
    "    }\n",
    "    api_url = f\"http://www.omdbapi.com/?i={imdb_id}&apikey=7d9eb382\"\n",
    "    response = requests.get(api_url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        movie_data = response.json()\n",
    "        if movie_data['Response'] == 'True':\n",
    "            new_movie = {\n",
    "                'Title': movie_data.get('Title', 'N/A'),\n",
    "                'Description': movie_data.get('Plot', 'N/A'),\n",
    "                'Genre': movie_data.get('Genre', 'N/A').split(', '),\n",
    "                'preprocessed_description': preprocess_text(movie_data.get('Plot', 'N/A'))\n",
    "            }\n",
    "            new_movie_df = pd.DataFrame([new_movie])\n",
    "            df = pd.concat([df, new_movie_df], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    imdb_link = input('Please paste your IMDb link here: ')\n",
    "    imdb_id = extract_imdb_id(imdb_link)\n",
    "    if imdb_id:\n",
    "        global df, combined_features, cosine_sim\n",
    "        df = fill_missing_info(df, imdb_id)\n",
    "        if not df.empty:\n",
    "            df['preprocessed_description'] = df['Description'].apply(preprocess_text)\n",
    "            combined_features = compute_features(df)\n",
    "            cosine_sim = cosine_similarity(combined_features, combined_features)\n",
    "            movie_title = df.iloc[-1]['Title']\n",
    "            print(\"Movie Title:\", movie_title)\n",
    "            print(\"DataFrame:\", df.iloc[-1])\n",
    "            recommendations = get_recommendations(movie_title, cosine_sim, df)\n",
    "            print(f\"Movies recommended for '{movie_title}':\")\n",
    "            recommended_titles = []\n",
    "            for idx, row in recommendations.iterrows():\n",
    "                if row['Title'] != movie_title and row['Title'] not in recommended_titles:\n",
    "                    recommended_titles.append(row['Title'])\n",
    "                    print(f\"Title: {row['Title']}\\n\"\n",
    "                          f\"Description: {row['Description']}\\n\"\n",
    "                          f\"Genre: {row['Genre']}\\n\"\n",
    "                          f\"Director: {row['Director']}\\n\"\n",
    "                          f\"Poster: {row['Poster']}\\n\")\n",
    "                    if len(recommended_titles) == 4:\n",
    "                        break\n",
    "        else:\n",
    "            print(\"Failed to retrieve movie information from IMDb.\")\n",
    "    else:\n",
    "        print(\"Invalid IMDb link. Please provide a valid IMDb link.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1577969-f753-421f-a139-bc4e3b321bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
