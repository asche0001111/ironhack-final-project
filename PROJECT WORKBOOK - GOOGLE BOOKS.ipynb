{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ec0bba7-cf48-48c2-8918-b77b65b3f808",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/akirichenko/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/akirichenko/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/akirichenko/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# NLTK setup\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"goodreads_data.csv\")\n",
    "df.drop(columns=[\"Unnamed: 0\", \"URL\"], inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df[\"Genres\"] = df[\"Genres\"].str.split(\", \").apply(lambda x: [genre.strip(\"[]\") for genre in x])\n",
    "df[\"Genres\"] = df[\"Genres\"].apply(lambda x: ', '.join(x))\n",
    "df[\"Genres\"] = df[\"Genres\"].apply(lambda x: x.replace(\"'\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff767762-4726-4437-a079-b5ff8e66d23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_book_details(volume_id):\n",
    "    url = f\"https://www.googleapis.com/books/v1/volumes/{volume_id}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddb298b5-6a43-483a-aa12-e7112c1f03d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_volume_id(url):\n",
    "    match = re.search(r'/books/edition/.+/([^/?]+)', url)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ae8bce5-c7c8-4239-ae24-1e747a8d12c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_book_data(book_data):\n",
    "    volume_info = book_data.get(\"volumeInfo\", {})\n",
    "    book = volume_info.get(\"title\", \"N/A\")\n",
    "    authors = \", \".join(volume_info.get(\"authors\", [\"N/A\"]))\n",
    "    description = volume_info.get(\"description\", \"N/A\")\n",
    "    genres = \", \".join(volume_info.get(\"categories\", [\"N/A\"]))\n",
    "    avg_rating = volume_info.get(\"averageRating\", \"N/A\")\n",
    "    \n",
    "    book_dict = {\n",
    "        \"Book\": book,\n",
    "        \"Author\": authors,\n",
    "        \"Description\": description,\n",
    "        \"Genres\": genres,\n",
    "        \"Avg_Rating\": avg_rating\n",
    "    }\n",
    "    \n",
    "    return book_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3541de-63e6-4d65-b829-0823ee450c22",
   "metadata": {},
   "source": [
    "def search_google_books(book_title, author):\n",
    "    query = f\"{book_title} {author}\"\n",
    "    url = f\"https://www.googleapis.com/books/v1/volumes?q={query}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        results = response.json().get(\"items\", [])\n",
    "        if results:\n",
    "            return results[0][\"volumeInfo\"].get(\"infoLink\", \"N/A\")\n",
    "    return \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86cfc6c7-d132-4dcd-90ee-d11d4af66c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_google_books(book_title, author):\n",
    "    query = f\"{book_title} {author}\"\n",
    "    url = f\"https://www.googleapis.com/books/v1/volumes?q={query}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        results = response.json().get(\"items\", [])\n",
    "        if results:\n",
    "            volume_info = results[0][\"volumeInfo\"]\n",
    "            info_link = volume_info.get(\"infoLink\", \"N/A\")\n",
    "            cover_url = volume_info[\"imageLinks\"].get(\"thumbnail\", \"N/A\") if \"imageLinks\" in volume_info else \"N/A\"\n",
    "            return cover_url, info_link\n",
    "    return \"N/A\", \"N/A\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bce2ad2-6575-4db2-a044-bb3c2cefe314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    if pd.isnull(text):  # Check if the text is NaN\n",
    "        return \"\"        # If NaN, return an empty string\n",
    "    \n",
    "    # Tokenize, lemmatize, and remove stopwords\n",
    "    tokens = word_tokenize(text)\n",
    "    clean_tokens = [lemmatizer.lemmatize(token.lower()) for token in tokens if token.isalnum() and token.lower() not in stop_words]\n",
    "    return \" \".join(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4893801f-9ab3-4270-bc5f-aa9b5a8a9d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(descriptions, genres):\n",
    "    # Vectorize text\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix_desc = tfidf_vectorizer.fit_transform(descriptions)\n",
    "    tfidf_matrix_genres = tfidf_vectorizer.fit_transform(genres)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    description_similarity = cosine_similarity(tfidf_matrix_desc)\n",
    "    genre_similarity = cosine_similarity(tfidf_matrix_genres)\n",
    "\n",
    "    return description_similarity, genre_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d5fd814-2fbd-411f-8402-54cb67691d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_recommendations(input_book_idx, book_data, description_similarity, genre_similarity):\n",
    "    combined_similarity = (description_similarity[input_book_idx] + genre_similarity[input_book_idx]) / 2\n",
    "\n",
    "    similar_indices = combined_similarity.argsort()[-4:-1][::-1]\n",
    "    similar_books = [(book_data.iloc[idx][\"Book\"], book_data.iloc[idx][\"Author\"]) for idx in similar_indices]\n",
    "\n",
    "    return similar_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09756a19-5817-4b68-8abf-8d3a4eca8373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Paste your Google Books URL here:  https://www.google.de/books/edition/Industrial_Society_and_Its_Future/9ja1zwEACAAJ?hl=en\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for 'Industrial Society and Its Future':\n",
      "Book: The Social Contract, Author: Jean-Jacques Rousseau, Link: https://play.google.com/store/books/details?id=GK1GAQAAMAAJ&source=gbs_api\n",
      "Book: Leviathan, Author: Thomas Hobbes, Link: https://play.google.com/store/books/details?id=RI9qEAAAQBAJ&source=gbs_api\n",
      "Book: The Prince, Author: Niccol√≤ Machiavelli, Link: http://books.google.de/books?id=bRdLCgAAQBAJ&dq=The+Prince+Niccol%C3%B2+Machiavelli&hl=&source=gbs_api\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    url = input(\"Paste your Google Books URL here: \")\n",
    "    volume_id = extract_volume_id(url)\n",
    "    book_data = fetch_book_details(volume_id)\n",
    "    formatted_data = format_book_data(book_data)\n",
    "\n",
    "    input_book = formatted_data[\"Book\"]\n",
    "    input_description = preprocess_text(formatted_data[\"Description\"])\n",
    "    input_genres = preprocess_text(formatted_data[\"Genres\"])\n",
    "\n",
    "    # Add input book's data to the dataframe using pd.concat\n",
    "    input_book_df = pd.DataFrame([{\n",
    "        \"Book\": input_book,\n",
    "        \"Description\": input_description,\n",
    "        \"Genres\": input_genres,\n",
    "        \"Author\": formatted_data[\"Author\"]\n",
    "    }])\n",
    "    \n",
    "    df_extended = pd.concat([df, input_book_df], ignore_index=True)\n",
    "\n",
    "    # Compute similarity\n",
    "    description_similarity, genre_similarity = compute_similarity(df_extended[\"Description\"], df_extended[\"Genres\"])\n",
    "\n",
    "    # Find recommendations\n",
    "    input_book_idx = df_extended.index[df_extended[\"Book\"] == input_book][0]\n",
    "    recommendations = find_recommendations(input_book_idx, df_extended, description_similarity, genre_similarity)\n",
    "    \n",
    "    print(f\"Recommendations for '{input_book}':\")\n",
    "    for book, author in recommendations:\n",
    "        link = search_google_books(book, author)\n",
    "        print(f\"Book: {book}, Author: {author}, Link: {link}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f20c2b8d-43ca-425b-ab2e-81ec1a949034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Paste your Google Books URL here:  https://www.google.de/books/edition/Industrial_Society_and_Its_Future/9ja1zwEACAAJ?hl=en\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for 'Industrial Society and Its Future':\n",
      "Title: The Social Contract\n",
      "Author: Jean-Jacques Rousseau\n",
      "Genres: Philosophy, Politics, Nonfiction, Classics, History, France, Political Science\n",
      "Cover: http://books.google.com/books/content?id=GK1GAQAAMAAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api\n",
      "Link: https://play.google.com/store/books/details?id=GK1GAQAAMAAJ&source=gbs_api\n",
      "\n",
      "Title: Leviathan\n",
      "Author: Thomas Hobbes\n",
      "Genres: Philosophy, Politics, Classics, Nonfiction, History, Political Science, School\n",
      "Cover: http://books.google.com/books/content?id=RI9qEAAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api\n",
      "Link: https://play.google.com/store/books/details?id=RI9qEAAAQBAJ&source=gbs_api\n",
      "\n",
      "Title: The Prince\n",
      "Author: Niccol√≤ Machiavelli\n",
      "Genres: Classics, Philosophy, Nonfiction, Politics, History, Literature, Political Science\n",
      "Cover: http://books.google.com/books/content?id=bRdLCgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api\n",
      "Link: http://books.google.de/books?id=bRdLCgAAQBAJ&dq=The+Prince+Niccol%C3%B2+Machiavelli&hl=&source=gbs_api\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    url = input(\"Paste your Google Books URL here: \")\n",
    "    volume_id = extract_volume_id(url)\n",
    "    book_data = fetch_book_details(volume_id)\n",
    "    formatted_data = format_book_data(book_data)\n",
    "\n",
    "    input_book = formatted_data[\"Book\"]\n",
    "    input_description = preprocess_text(formatted_data[\"Description\"])\n",
    "    input_genres = preprocess_text(formatted_data[\"Genres\"])\n",
    "\n",
    "    # Add input book's data to the dataframe using pd.concat\n",
    "    input_book_df = pd.DataFrame([{\n",
    "        \"Book\": input_book,\n",
    "        \"Description\": input_description,\n",
    "        \"Genres\": input_genres,\n",
    "        \"Author\": formatted_data[\"Author\"]\n",
    "    }])\n",
    "    \n",
    "    df_extended = pd.concat([df, input_book_df], ignore_index=True)\n",
    "\n",
    "    # Compute similarity\n",
    "    description_similarity, genre_similarity = compute_similarity(df_extended[\"Description\"], df_extended[\"Genres\"])\n",
    "\n",
    "    # Find recommendations\n",
    "    input_book_idx = df_extended.index[df_extended[\"Book\"] == input_book][0]\n",
    "    recommendations = find_recommendations(input_book_idx, df_extended, description_similarity, genre_similarity)\n",
    "    \n",
    "    print(f\"Recommendations for '{input_book}':\")\n",
    "    for book, author in recommendations:\n",
    "        cover_url, book_url = search_google_books(book, author)\n",
    "        print(f\"Title: {book}\")\n",
    "        print(f\"Author: {author}\")\n",
    "        print(f\"Genres: {df_extended[df_extended['Book'] == book]['Genres'].values[0]}\")\n",
    "        print(f\"Cover: {cover_url}\")\n",
    "        print(f\"Link: {book_url}\")\n",
    "        print()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947041af-94e5-488d-b6cc-1296ef6fcf7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
