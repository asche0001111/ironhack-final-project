{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "967c87cc-04e0-40da-aa0d-6b24dd76d446",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/akirichenko/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/akirichenko/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/akirichenko/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import ast\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Sample book data (replace with your dataset)\n",
    "df = pd.read_csv(\"goodreads_data.csv\")\n",
    "df.drop(columns = [\"Unnamed: 0\", \"URL\"], inplace = True)\n",
    "df.dropna(inplace = True)\n",
    "df[\"Genres\"] = df[\"Genres\"].str.split(\", \").apply(lambda x: [genre.strip(\"[]\") for genre in x])\n",
    "df[\"Genres\"] = df[\"Genres\"].apply(lambda x: ', '.join(x))\n",
    "df[\"Genres\"] = df[\"Genres\"].apply(lambda x: x.replace(\"'\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "b5ee3f23-7b65-489f-b7f3-56d94a71dc28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book</th>\n",
       "      <th>Author</th>\n",
       "      <th>Description</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Avg_Rating</th>\n",
       "      <th>Num_Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>The unforgettable novel of a childhood in a sl...</td>\n",
       "      <td>Classics, Fiction, Historical Fiction, School,...</td>\n",
       "      <td>4.27</td>\n",
       "      <td>5,691,311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Philosopher’s Stone (Harr...</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>Harry Potter thinks he is an ordinary boy - un...</td>\n",
       "      <td>Fantasy, Fiction, Young Adult, Magic, Children...</td>\n",
       "      <td>4.47</td>\n",
       "      <td>9,278,135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>Since its immediate success in 1813, Pride and...</td>\n",
       "      <td>Classics, Fiction, Romance, Historical Fiction...</td>\n",
       "      <td>4.28</td>\n",
       "      <td>3,944,155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Diary of a Young Girl</td>\n",
       "      <td>Anne Frank</td>\n",
       "      <td>Discovered in the attic in which she spent the...</td>\n",
       "      <td>Classics, Nonfiction, History, Biography, Memo...</td>\n",
       "      <td>4.18</td>\n",
       "      <td>3,488,438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal Farm</td>\n",
       "      <td>George Orwell</td>\n",
       "      <td>Librarian's note: There is an Alternate Cover ...</td>\n",
       "      <td>Classics, Fiction, Dystopia, Fantasy, Politics...</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3,575,172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Breeders (Breeders Trilogy, #1)</td>\n",
       "      <td>Ashley Quigley</td>\n",
       "      <td>How far would you go? If human society was gen...</td>\n",
       "      <td>Dystopia, Science Fiction, Post Apocalyptic, P...</td>\n",
       "      <td>3.44</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Dynamo</td>\n",
       "      <td>Eleanor Gustafson</td>\n",
       "      <td>Jeth Cavanaugh is searching for a new life alo...</td>\n",
       "      <td></td>\n",
       "      <td>4.23</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>The Republic of Trees</td>\n",
       "      <td>Sam Taylor</td>\n",
       "      <td>This dark fable tells the story of four Englis...</td>\n",
       "      <td>Fiction, Horror, Dystopia, Coming Of Age</td>\n",
       "      <td>3.29</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Waking Up (Healing Hearts, #1)</td>\n",
       "      <td>Renee Dyer</td>\n",
       "      <td>For Adriana Monroe life couldn’t get any bette...</td>\n",
       "      <td>New Adult, Romance, Contemporary Romance, Cont...</td>\n",
       "      <td>4.13</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Bits and Pieces: Tales and Sonnets</td>\n",
       "      <td>Jas T. Ward</td>\n",
       "      <td>After demands of thousands of fans in various ...</td>\n",
       "      <td></td>\n",
       "      <td>5.00</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9923 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Book             Author  \\\n",
       "0                                 To Kill a Mockingbird         Harper Lee   \n",
       "1     Harry Potter and the Philosopher’s Stone (Harr...       J.K. Rowling   \n",
       "2                                   Pride and Prejudice        Jane Austen   \n",
       "3                             The Diary of a Young Girl         Anne Frank   \n",
       "4                                           Animal Farm      George Orwell   \n",
       "...                                                 ...                ...   \n",
       "9995                    Breeders (Breeders Trilogy, #1)     Ashley Quigley   \n",
       "9996                                             Dynamo  Eleanor Gustafson   \n",
       "9997                              The Republic of Trees         Sam Taylor   \n",
       "9998                     Waking Up (Healing Hearts, #1)         Renee Dyer   \n",
       "9999                 Bits and Pieces: Tales and Sonnets        Jas T. Ward   \n",
       "\n",
       "                                            Description  \\\n",
       "0     The unforgettable novel of a childhood in a sl...   \n",
       "1     Harry Potter thinks he is an ordinary boy - un...   \n",
       "2     Since its immediate success in 1813, Pride and...   \n",
       "3     Discovered in the attic in which she spent the...   \n",
       "4     Librarian's note: There is an Alternate Cover ...   \n",
       "...                                                 ...   \n",
       "9995  How far would you go? If human society was gen...   \n",
       "9996  Jeth Cavanaugh is searching for a new life alo...   \n",
       "9997  This dark fable tells the story of four Englis...   \n",
       "9998  For Adriana Monroe life couldn’t get any bette...   \n",
       "9999  After demands of thousands of fans in various ...   \n",
       "\n",
       "                                                 Genres  Avg_Rating  \\\n",
       "0     Classics, Fiction, Historical Fiction, School,...        4.27   \n",
       "1     Fantasy, Fiction, Young Adult, Magic, Children...        4.47   \n",
       "2     Classics, Fiction, Romance, Historical Fiction...        4.28   \n",
       "3     Classics, Nonfiction, History, Biography, Memo...        4.18   \n",
       "4     Classics, Fiction, Dystopia, Fantasy, Politics...        3.98   \n",
       "...                                                 ...         ...   \n",
       "9995  Dystopia, Science Fiction, Post Apocalyptic, P...        3.44   \n",
       "9996                                                           4.23   \n",
       "9997           Fiction, Horror, Dystopia, Coming Of Age        3.29   \n",
       "9998  New Adult, Romance, Contemporary Romance, Cont...        4.13   \n",
       "9999                                                           5.00   \n",
       "\n",
       "     Num_Ratings  \n",
       "0      5,691,311  \n",
       "1      9,278,135  \n",
       "2      3,944,155  \n",
       "3      3,488,438  \n",
       "4      3,575,172  \n",
       "...          ...  \n",
       "9995         276  \n",
       "9996          60  \n",
       "9997         383  \n",
       "9998         263  \n",
       "9999          36  \n",
       "\n",
       "[9923 rows x 6 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "20a26f59-18e3-4592-9b87-9daded57b3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Classics, Fiction, Historical Fiction, School, Literature, Young Adult, Historical'"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Genres\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "65dcb8b5-f2a6-47d9-83cb-c7debdd8757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_book_details(volume_id):\n",
    "    url = f\"https://www.googleapis.com/books/v1/volumes/{volume_id}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "29d5b73b-f602-4d6f-977c-d3b51d3323f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_volume_id(url):\n",
    "    match = re.search(r'/books/edition/.+/([^/?]+)', url)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "68a6d4df-44f6-4373-b18a-978c7ba35c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_book_data(book_data):\n",
    "    volume_info = book_data.get(\"volumeInfo\", {})\n",
    "    book = volume_info.get(\"title\", \"N/A\")\n",
    "    authors = \", \".join(volume_info.get(\"authors\", [\"N/A\"]))\n",
    "    description = volume_info.get(\"description\", \"N/A\")\n",
    "    genres = \", \".join(volume_info.get(\"categories\", [\"N/A\"]))\n",
    "    avg_rating = volume_info.get(\"averageRating\", \"N/A\")\n",
    "    \n",
    "    book_dict = {\n",
    "        \"Book\": book,\n",
    "        \"Author\": authors,\n",
    "        \"Description\": description,\n",
    "        \"Genres\": genres,\n",
    "        \"Avg_Rating\": avg_rating\n",
    "    }\n",
    "    \n",
    "    return book_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "cb3fb1bc-766c-4e86-976c-42c31301e522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    if pd.isnull(text):  # Check if the text is NaN\n",
    "        return \"\"        # If NaN, return an empty string\n",
    "    \n",
    "    # Remove square brackets and split by commas\n",
    "    cleaned_text = text.strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
    "    \n",
    "    # Tokenize each genre\n",
    "    tokens = [token.strip() for token in cleaned_text]\n",
    "    \n",
    "    # Lowercase and remove stopwords/punctuation\n",
    "    clean_tokens = [lemmatizer.lemmatize(token.lower()) for token in tokens if token.isalnum() and token.lower() not in stop_words]\n",
    "    return \" \".join(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "8852d8d6-2286-45a8-8aa5-dd06b45f5759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(descriptions, genres):\n",
    "    # Vectorize text\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(descriptions)\n",
    "\n",
    "    # Compute cosine similarity for descriptions\n",
    "    description_similarity = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "    # Compute cosine similarity for genres\n",
    "\n",
    "    tfidf_vectorizer_genres = TfidfVectorizer()\n",
    "    tfidf_matrix_genres = tfidf_vectorizer.fit_transform(genres)\n",
    "    genre_similarity = cosine_similarity(tfidf_matrix_genres, tfidf_matrix_genres)\n",
    "\n",
    "    return description_similarity, genre_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "4e2af2e6-e65e-4982-94ca-b2f6c54d4508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_recommendations(input_book, book_data, description_similarity, genre_similarity):\n",
    "    input_index = book_data.index[book_data[\"Book\"] == input_book][0]\n",
    "\n",
    "    combined_similarity = (description_similarity[input_index] + genre_similarity[input_index]) / 2\n",
    "\n",
    "    similar_indices = combined_similarity.argsort()[-4:-1][::-1] \n",
    "    similar_books = [(book_data.iloc[idx][\"Book\"], combined_similarity[idx]) for idx in similar_indices]\n",
    "\n",
    "    return similar_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "e7fc092c-07dd-4d43-afa6-f42e3e6d32f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    url = input(\"Paste your Google Books URL here: \")\n",
    "    volume_id = extract_volume_id(url)\n",
    "    book_data = fetch_book_details(volume_id)\n",
    "    formatted_data = format_book_data(book_data)\n",
    "\n",
    "    input_book = formatted_data[\"Book\"]\n",
    "    input_description = preprocess_text(formatted_data[\"Description\"])\n",
    "    input_genres = preprocess_text(formatted_data[\"Genres\"])\n",
    "\n",
    "    # Compute similarity\n",
    "    description_similarity, genre_similarity = compute_similarity(df[\"Description\"], df[\"Genres\"])\n",
    "\n",
    "    # Find recommendations\n",
    "    recommendations = find_recommendations(input_book, df, description_similarity, genre_similarity)\n",
    "    print(f\"Recommendations for '{input_book}':\")\n",
    "    for book, similarity in recommendations:\n",
    "        print(f\"Book: {book}, Similarity: {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "9156f938-9832-4bea-94be-fc3764d5df6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Paste your Google Books URL here:  https://www.google.de/books/edition/Industrial_Society_and_Its_Future/9ja1zwEACAAJ?hl=en\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[199], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[198], line 12\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m input_genres \u001b[38;5;241m=\u001b[39m preprocess_text(formatted_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenres\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Compute similarity\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m description_similarity, genre_similarity \u001b[38;5;241m=\u001b[39m compute_similarity(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDescription\u001b[39m\u001b[38;5;124m\"\u001b[39m], df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenres\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Find recommendations\u001b[39;00m\n\u001b[1;32m     15\u001b[0m recommendations \u001b[38;5;241m=\u001b[39m find_recommendations(input_book, df, description_similarity, genre_similarity)\n",
      "Cell \u001b[0;32mIn[196], line 13\u001b[0m, in \u001b[0;36mcompute_similarity\u001b[0;34m(descriptions, genres)\u001b[0m\n\u001b[1;32m     11\u001b[0m tfidf_vectorizer_genres \u001b[38;5;241m=\u001b[39m TfidfVectorizer()\n\u001b[1;32m     12\u001b[0m tfidf_matrix_genres \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(genres)\n\u001b[0;32m---> 13\u001b[0m genre_similarity \u001b[38;5;241m=\u001b[39m cosine_similarity(tfidf_matrix_genres, tfidf_matrix_genres)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m description_similarity, genre_similarity\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:1401\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1399\u001b[0m     Y_normalized \u001b[38;5;241m=\u001b[39m normalize(Y, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 1401\u001b[0m K \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X_normalized, Y_normalized\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39mdense_output)\n\u001b[1;32m   1403\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m K\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:189\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    187\u001b[0m         ret \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(a, b)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 189\u001b[0m     ret \u001b[38;5;241m=\u001b[39m a \u001b[38;5;241m@\u001b[39m b\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    192\u001b[0m     sparse\u001b[38;5;241m.\u001b[39missparse(a)\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    196\u001b[0m ):\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/sparse/_base.py:624\u001b[0m, in \u001b[0;36m_spbase.__matmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScalar operands are not allowed, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    623\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 624\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mul_dispatch(other)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/sparse/_base.py:535\u001b[0m, in \u001b[0;36m_spbase._mul_dispatch\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m other\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdimension mismatch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mul_sparse_matrix(other)\n\u001b[1;32m    537\u001b[0m \u001b[38;5;66;03m# If it's a list or whatever, treat it like an array\u001b[39;00m\n\u001b[1;32m    538\u001b[0m other_a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(other)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/sparse/_compressed.py:517\u001b[0m, in \u001b[0;36m_cs_matrix._mul_sparse_matrix\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    513\u001b[0m idx_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_index_dtype((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindptr, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices,\n\u001b[1;32m    514\u001b[0m                              other\u001b[38;5;241m.\u001b[39mindptr, other\u001b[38;5;241m.\u001b[39mindices))\n\u001b[1;32m    516\u001b[0m fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_sparsetools, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_matmat_maxnnz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 517\u001b[0m nnz \u001b[38;5;241m=\u001b[39m fn(M, N,\n\u001b[1;32m    518\u001b[0m          np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindptr, dtype\u001b[38;5;241m=\u001b[39midx_dtype),\n\u001b[1;32m    519\u001b[0m          np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices, dtype\u001b[38;5;241m=\u001b[39midx_dtype),\n\u001b[1;32m    520\u001b[0m          np\u001b[38;5;241m.\u001b[39masarray(other\u001b[38;5;241m.\u001b[39mindptr, dtype\u001b[38;5;241m=\u001b[39midx_dtype),\n\u001b[1;32m    521\u001b[0m          np\u001b[38;5;241m.\u001b[39masarray(other\u001b[38;5;241m.\u001b[39mindices, dtype\u001b[38;5;241m=\u001b[39midx_dtype))\n\u001b[1;32m    523\u001b[0m idx_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_index_dtype((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindptr, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices,\n\u001b[1;32m    524\u001b[0m                              other\u001b[38;5;241m.\u001b[39mindptr, other\u001b[38;5;241m.\u001b[39mindices),\n\u001b[1;32m    525\u001b[0m                             maxval\u001b[38;5;241m=\u001b[39mnnz)\n\u001b[1;32m    527\u001b[0m indptr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(major_axis \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39midx_dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "58fcb385-b51a-4faf-b38f-3c317decd61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/akirichenko/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/akirichenko/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/akirichenko/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Paste your Google Books URL here:  https://www.google.de/books/edition/Industrial_Society_and_Its_Future/9ja1zwEACAAJ?hl=en\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for 'Industrial Society and Its Future':\n",
      "Book: The Social Contract, Similarity: 0.15005458661282167\n",
      "Book: Leviathan, Similarity: 0.14608071181760068\n",
      "Book: The Prince, Similarity: 0.14595345873246726\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# NLTK setup\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"goodreads_data.csv\")\n",
    "df.drop(columns=[\"Unnamed: 0\", \"URL\"], inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df[\"Genres\"] = df[\"Genres\"].str.split(\", \").apply(lambda x: [genre.strip(\"[]\") for genre in x])\n",
    "df[\"Genres\"] = df[\"Genres\"].apply(lambda x: ', '.join(x))\n",
    "df[\"Genres\"] = df[\"Genres\"].apply(lambda x: x.replace(\"'\", \"\"))\n",
    "\n",
    "def fetch_book_details(volume_id):\n",
    "    url = f\"https://www.googleapis.com/books/v1/volumes/{volume_id}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extract_volume_id(url):\n",
    "    match = re.search(r'/books/edition/.+/([^/?]+)', url)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def format_book_data(book_data):\n",
    "    volume_info = book_data.get(\"volumeInfo\", {})\n",
    "    book = volume_info.get(\"title\", \"N/A\")\n",
    "    authors = \", \".join(volume_info.get(\"authors\", [\"N/A\"]))\n",
    "    description = volume_info.get(\"description\", \"N/A\")\n",
    "    genres = \", \".join(volume_info.get(\"categories\", [\"N/A\"]))\n",
    "    avg_rating = volume_info.get(\"averageRating\", \"N/A\")\n",
    "    \n",
    "    book_dict = {\n",
    "        \"Book\": book,\n",
    "        \"Author\": authors,\n",
    "        \"Description\": description,\n",
    "        \"Genres\": genres,\n",
    "        \"Avg_Rating\": avg_rating\n",
    "    }\n",
    "    \n",
    "    return book_dict\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if pd.isnull(text):  # Check if the text is NaN\n",
    "        return \"\"        # If NaN, return an empty string\n",
    "    \n",
    "    # Tokenize, lemmatize, and remove stopwords\n",
    "    tokens = word_tokenize(text)\n",
    "    clean_tokens = [lemmatizer.lemmatize(token.lower()) for token in tokens if token.isalnum() and token.lower() not in stop_words]\n",
    "    return \" \".join(clean_tokens)\n",
    "\n",
    "def compute_similarity(descriptions, genres):\n",
    "    # Vectorize text\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix_desc = tfidf_vectorizer.fit_transform(descriptions)\n",
    "    tfidf_matrix_genres = tfidf_vectorizer.fit_transform(genres)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    description_similarity = cosine_similarity(tfidf_matrix_desc)\n",
    "    genre_similarity = cosine_similarity(tfidf_matrix_genres)\n",
    "\n",
    "    return description_similarity, genre_similarity\n",
    "\n",
    "def find_recommendations(input_book_idx, book_data, description_similarity, genre_similarity):\n",
    "    combined_similarity = (description_similarity[input_book_idx] + genre_similarity[input_book_idx]) / 2\n",
    "\n",
    "    similar_indices = combined_similarity.argsort()[-4:-1][::-1]\n",
    "    similar_books = [(book_data.iloc[idx][\"Book\"], combined_similarity[idx]) for idx in similar_indices]\n",
    "\n",
    "    return similar_books\n",
    "\n",
    "def main():\n",
    "    url = input(\"Paste your Google Books URL here: \")\n",
    "    volume_id = extract_volume_id(url)\n",
    "    book_data = fetch_book_details(volume_id)\n",
    "    formatted_data = format_book_data(book_data)\n",
    "\n",
    "    input_book = formatted_data[\"Book\"]\n",
    "    input_description = preprocess_text(formatted_data[\"Description\"])\n",
    "    input_genres = preprocess_text(formatted_data[\"Genres\"])\n",
    "\n",
    "    # Add input book's data to the dataframe using pd.concat\n",
    "    input_book_df = pd.DataFrame([{\n",
    "        \"Book\": input_book,\n",
    "        \"Description\": input_description,\n",
    "        \"Genres\": input_genres\n",
    "    }])\n",
    "    \n",
    "    df_extended = pd.concat([df, input_book_df], ignore_index=True)\n",
    "\n",
    "    # Compute similarity\n",
    "    description_similarity, genre_similarity = compute_similarity(df_extended[\"Description\"], df_extended[\"Genres\"])\n",
    "\n",
    "    # Find recommendations\n",
    "    input_book_idx = df_extended.index[df_extended[\"Book\"] == input_book][0]\n",
    "    recommendations = find_recommendations(input_book_idx, df_extended, description_similarity, genre_similarity)\n",
    "    print(f\"Recommendations for '{input_book}':\")\n",
    "    for book, similarity in recommendations:\n",
    "        print(f\"Book: {book}, Similarity: {similarity}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "b61c4d52-3ba3-46e9-814b-7e37636f0d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/akirichenko/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/akirichenko/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/akirichenko/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Paste your Google Books URL here:  https://www.google.de/books/edition/Industrial_Society_and_Its_Future/9ja1zwEACAAJ?hl=en\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for 'Industrial Society and Its Future':\n",
      "Book: The Social Contract, Author: Jean-Jacques Rousseau\n",
      "Book: Leviathan, Author: Thomas Hobbes\n",
      "Book: The Prince, Author: Niccolò Machiavelli\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# NLTK setup\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"goodreads_data.csv\")\n",
    "df.drop(columns=[\"Unnamed: 0\", \"URL\"], inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df[\"Genres\"] = df[\"Genres\"].str.split(\", \").apply(lambda x: [genre.strip(\"[]\") for genre in x])\n",
    "df[\"Genres\"] = df[\"Genres\"].apply(lambda x: ', '.join(x))\n",
    "df[\"Genres\"] = df[\"Genres\"].apply(lambda x: x.replace(\"'\", \"\"))\n",
    "\n",
    "def fetch_book_details(volume_id):\n",
    "    url = f\"https://www.googleapis.com/books/v1/volumes/{volume_id}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extract_volume_id(url):\n",
    "    match = re.search(r'/books/edition/.+/([^/?]+)', url)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def format_book_data(book_data):\n",
    "    volume_info = book_data.get(\"volumeInfo\", {})\n",
    "    book = volume_info.get(\"title\", \"N/A\")\n",
    "    authors = \", \".join(volume_info.get(\"authors\", [\"N/A\"]))\n",
    "    description = volume_info.get(\"description\", \"N/A\")\n",
    "    genres = \", \".join(volume_info.get(\"categories\", [\"N/A\"]))\n",
    "    avg_rating = volume_info.get(\"averageRating\", \"N/A\")\n",
    "    \n",
    "    book_dict = {\n",
    "        \"Book\": book,\n",
    "        \"Author\": authors,\n",
    "        \"Description\": description,\n",
    "        \"Genres\": genres,\n",
    "        \"Avg_Rating\": avg_rating\n",
    "    }\n",
    "    \n",
    "    return book_dict\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if pd.isnull(text):  # Check if the text is NaN\n",
    "        return \"\"        # If NaN, return an empty string\n",
    "    \n",
    "    # Tokenize, lemmatize, and remove stopwords\n",
    "    tokens = word_tokenize(text)\n",
    "    clean_tokens = [lemmatizer.lemmatize(token.lower()) for token in tokens if token.isalnum() and token.lower() not in stop_words]\n",
    "    return \" \".join(clean_tokens)\n",
    "\n",
    "def compute_similarity(descriptions, genres):\n",
    "    # Vectorize text\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix_desc = tfidf_vectorizer.fit_transform(descriptions)\n",
    "    tfidf_matrix_genres = tfidf_vectorizer.fit_transform(genres)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    description_similarity = cosine_similarity(tfidf_matrix_desc)\n",
    "    genre_similarity = cosine_similarity(tfidf_matrix_genres)\n",
    "\n",
    "    return description_similarity, genre_similarity\n",
    "\n",
    "def find_recommendations(input_book_idx, book_data, description_similarity, genre_similarity):\n",
    "    combined_similarity = (description_similarity[input_book_idx] + genre_similarity[input_book_idx]) / 2\n",
    "\n",
    "    similar_indices = combined_similarity.argsort()[-4:-1][::-1]\n",
    "    similar_books = [(book_data.iloc[idx][\"Book\"], book_data.iloc[idx][\"Author\"]) for idx in similar_indices]\n",
    "\n",
    "    return similar_books\n",
    "\n",
    "def main():\n",
    "    url = input(\"Paste your Google Books URL here: \")\n",
    "    volume_id = extract_volume_id(url)\n",
    "    book_data = fetch_book_details(volume_id)\n",
    "    formatted_data = format_book_data(book_data)\n",
    "\n",
    "    input_book = formatted_data[\"Book\"]\n",
    "    input_description = preprocess_text(formatted_data[\"Description\"])\n",
    "    input_genres = preprocess_text(formatted_data[\"Genres\"])\n",
    "\n",
    "    # Add input book's data to the dataframe using pd.concat\n",
    "    input_book_df = pd.DataFrame([{\n",
    "        \"Book\": input_book,\n",
    "        \"Description\": input_description,\n",
    "        \"Genres\": input_genres,\n",
    "        \"Author\": formatted_data[\"Author\"]  # Add author information\n",
    "    }])\n",
    "    \n",
    "    df_extended = pd.concat([df, input_book_df], ignore_index=True)\n",
    "\n",
    "    # Compute similarity\n",
    "    description_similarity, genre_similarity = compute_similarity(df_extended[\"Description\"], df_extended[\"Genres\"])\n",
    "\n",
    "    # Find recommendations\n",
    "    input_book_idx = df_extended.index[df_extended[\"Book\"] == input_book][0]\n",
    "    recommendations = find_recommendations(input_book_idx, df_extended, description_similarity, genre_similarity)\n",
    "    print(f\"Recommendations for '{input_book}':\")\n",
    "    for book, author in recommendations:\n",
    "        print(f\"Book: {book}, Author: {author}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "7608c59e-65f9-4bb9-bcf9-dc37cc204397",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/akirichenko/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/akirichenko/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/akirichenko/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Paste your Google Books URL here:  https://www.google.de/books/edition/Industrial_Society_and_Its_Future/9ja1zwEACAAJ?hl=en\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for 'Industrial Society and Its Future':\n",
      "Book: The Social Contract, Author: Jean-Jacques Rousseau, Link: https://play.google.com/store/books/details?id=GK1GAQAAMAAJ&source=gbs_api\n",
      "Book: Leviathan, Author: Thomas Hobbes, Link: https://play.google.com/store/books/details?id=RI9qEAAAQBAJ&source=gbs_api\n",
      "Book: The Prince, Author: Niccolò Machiavelli, Link: http://books.google.de/books?id=bRdLCgAAQBAJ&dq=The+Prince+Niccol%C3%B2+Machiavelli&hl=&source=gbs_api\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# NLTK setup\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"goodreads_data.csv\")\n",
    "df.drop(columns=[\"Unnamed: 0\", \"URL\"], inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df[\"Genres\"] = df[\"Genres\"].str.split(\", \").apply(lambda x: [genre.strip(\"[]\") for genre in x])\n",
    "df[\"Genres\"] = df[\"Genres\"].apply(lambda x: ', '.join(x))\n",
    "df[\"Genres\"] = df[\"Genres\"].apply(lambda x: x.replace(\"'\", \"\"))\n",
    "\n",
    "def fetch_book_details(volume_id):\n",
    "    url = f\"https://www.googleapis.com/books/v1/volumes/{volume_id}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extract_volume_id(url):\n",
    "    match = re.search(r'/books/edition/.+/([^/?]+)', url)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def format_book_data(book_data):\n",
    "    volume_info = book_data.get(\"volumeInfo\", {})\n",
    "    book = volume_info.get(\"title\", \"N/A\")\n",
    "    authors = \", \".join(volume_info.get(\"authors\", [\"N/A\"]))\n",
    "    description = volume_info.get(\"description\", \"N/A\")\n",
    "    genres = \", \".join(volume_info.get(\"categories\", [\"N/A\"]))\n",
    "    avg_rating = volume_info.get(\"averageRating\", \"N/A\")\n",
    "    \n",
    "    book_dict = {\n",
    "        \"Book\": book,\n",
    "        \"Author\": authors,\n",
    "        \"Description\": description,\n",
    "        \"Genres\": genres,\n",
    "        \"Avg_Rating\": avg_rating\n",
    "    }\n",
    "    \n",
    "    return book_dict\n",
    "\n",
    "def search_google_books(book_title, author):\n",
    "    query = f\"{book_title} {author}\"\n",
    "    url = f\"https://www.googleapis.com/books/v1/volumes?q={query}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        results = response.json().get(\"items\", [])\n",
    "        if results:\n",
    "            return results[0][\"volumeInfo\"].get(\"infoLink\", \"N/A\")\n",
    "    return \"N/A\"\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if pd.isnull(text):  # Check if the text is NaN\n",
    "        return \"\"        # If NaN, return an empty string\n",
    "    \n",
    "    # Tokenize, lemmatize, and remove stopwords\n",
    "    tokens = word_tokenize(text)\n",
    "    clean_tokens = [lemmatizer.lemmatize(token.lower()) for token in tokens if token.isalnum() and token.lower() not in stop_words]\n",
    "    return \" \".join(clean_tokens)\n",
    "\n",
    "def compute_similarity(descriptions, genres):\n",
    "    # Vectorize text\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix_desc = tfidf_vectorizer.fit_transform(descriptions)\n",
    "    tfidf_matrix_genres = tfidf_vectorizer.fit_transform(genres)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    description_similarity = cosine_similarity(tfidf_matrix_desc)\n",
    "    genre_similarity = cosine_similarity(tfidf_matrix_genres)\n",
    "\n",
    "    return description_similarity, genre_similarity\n",
    "\n",
    "def find_recommendations(input_book_idx, book_data, description_similarity, genre_similarity):\n",
    "    combined_similarity = (description_similarity[input_book_idx] + genre_similarity[input_book_idx]) / 2\n",
    "\n",
    "    similar_indices = combined_similarity.argsort()[-4:-1][::-1]\n",
    "    similar_books = [(book_data.iloc[idx][\"Book\"], book_data.iloc[idx][\"Author\"]) for idx in similar_indices]\n",
    "\n",
    "    return similar_books\n",
    "\n",
    "def main():\n",
    "    url = input(\"Paste your Google Books URL here: \")\n",
    "    volume_id = extract_volume_id(url)\n",
    "    book_data = fetch_book_details(volume_id)\n",
    "    formatted_data = format_book_data(book_data)\n",
    "\n",
    "    input_book = formatted_data[\"Book\"]\n",
    "    input_description = preprocess_text(formatted_data[\"Description\"])\n",
    "    input_genres = preprocess_text(formatted_data[\"Genres\"])\n",
    "\n",
    "    # Add input book's data to the dataframe using pd.concat\n",
    "    input_book_df = pd.DataFrame([{\n",
    "        \"Book\": input_book,\n",
    "        \"Description\": input_description,\n",
    "        \"Genres\": input_genres,\n",
    "        \"Author\": formatted_data[\"Author\"]\n",
    "    }])\n",
    "    \n",
    "    df_extended = pd.concat([df, input_book_df], ignore_index=True)\n",
    "\n",
    "    # Compute similarity\n",
    "    description_similarity, genre_similarity = compute_similarity(df_extended[\"Description\"], df_extended[\"Genres\"])\n",
    "\n",
    "    # Find recommendations\n",
    "    input_book_idx = df_extended.index[df_extended[\"Book\"] == input_book][0]\n",
    "    recommendations = find_recommendations(input_book_idx, df_extended, description_similarity, genre_similarity)\n",
    "    \n",
    "    print(f\"Recommendations for '{input_book}':\")\n",
    "    for book, author in recommendations:\n",
    "        link = search_google_books(book, author)\n",
    "        print(f\"Book: {book}, Author: {author}, Link: {link}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec0bba7-cf48-48c2-8918-b77b65b3f808",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
